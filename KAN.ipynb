{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# KAN: Kolmogorov–Arnold Networks\n",
    "## 樊豫龙 毛奕婷 黄颖 王一诺\n",
    "## [引用]arXiv:2404.19756v2 [cs.LG] 2 May 2024\n",
    "### Tips:\n",
    "### 我们将KANLayer.py中的参数精度设置为64位，即FloatTensor改成了DoubleTensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e09462c6681b3239"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kolmogorov-Arnold表示定理\n",
    "Kolmogorov-Arnold定理表明，如果$f$是一个定义在有界域上的多元连续函数，那么它可以被表示为单变量连续函数和加法的有限组合。更具体地说，对于一个光滑的函数，存在一系列单变量连续函数和加法操作，将其表示为有限次的组合。更详细的，可以表示为下列函数$f : [0,1]^n \\to \\mathbb{R}$：\n",
    "$$f(x) = f(x_1,...,x_n)=\\sum_{q=1}^{2n+1}\\Phi_q(\\sum_{p=1}^n \\phi_{q,p}(x_p))$$\n",
    "在这段文字中，提到了函数$\\phi_{q,p}:[0,1]\\to\\mathbb{R}$ 和 $\\Phi_q:\\mathbb{R}\\to\\mathbb{R}$，从某种意义上说，他们表明唯一真正的多元函数是加法，因为每个其他函数都可以用单变量函数和求和来表示。然而，这种 2 层宽度为 (2n+1) 的Kolmogorov–Arnold表示可能由于其有限的表达能力而不平滑。我们通过将其概括到任意深度和宽度来增强其表达能力。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93fbb71ef3f91e15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kolmogorov-Arnold Network\n",
    "## KAN 网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99a5e6ec16c84161"
  },
  {
   "cell_type": "markdown",
   "source": [
    "科尔莫戈洛夫-阿诺尔德表示可以用矩阵形式表示如下：\n",
    "\n",
    "$$f(x)={\\bf \\Phi}_{\\rm out}\\circ{\\bf \\Phi}_{\\rm in}\\circ {\\bf x}$$\n",
    "\n",
    "其中\n",
    "\n",
    "$${\\bf \\Phi}_{\\rm in}= \\begin{pmatrix} \\phi_{1,1}(\\cdot) & \\cdots & \\phi_{1,n}(\\cdot) \\\\ \\vdots & & \\vdots \\\\ \\phi_{2n+1,1}(\\cdot) & \\cdots & \\phi_{2n+1,n}(\\cdot) \\end{pmatrix},\\quad {\\bf \\Phi}_{\\rm out}=\\begin{pmatrix} \\Phi_1(\\cdot) & \\cdots & \\Phi_{2n+1}(\\cdot)\\end{pmatrix}$$\n",
    "\n",
    "我们注意到 ${\\bf \\Phi}_{\\rm in}$ 和 ${\\bf \\Phi}_{\\rm out}$ 都是以下函数矩阵 ${\\bf \\Phi}$（具有 $n_{\\rm in}$ 个输入和 $n_{\\rm out}$ 个输出）的特殊情况，我们称之为科尔莫戈洛夫-阿诺尔德层：\n",
    "\n",
    "$${\\bf \\Phi}= \\begin{pmatrix} \\phi_{1,1}(\\cdot) & \\cdots & \\phi_{1,n_{\\rm in}}(\\cdot) \\\\ \\vdots & & \\vdots \\\\ \\phi_{n_{\\rm out},1}(\\cdot) & \\cdots & \\phi_{n_{\\rm out},n_{\\rm in}}(\\cdot) \\end{pmatrix}$$\n",
    "\n",
    "${\\bf \\Phi}_{\\rm in}$ 对应于 $n_{\\rm in}=n, n_{\\rm out}=2n+1$，而 ${\\bf \\Phi}_{\\rm out}$ 对应于 $n_{\\rm in}=2n+1, n_{\\rm out}=1$。\n",
    "\n",
    "定义完层以后，我们可以通过堆叠层来构建科尔莫戈洛夫-阿诺尔德网络。假设我们有 $L$ 个层，第 $l$ 层 ${\\bf \\Phi}_l$ 的形状为 $(n_{l+1}, n_{l})$。那么整个网络为\n",
    "\n",
    "$${\\rm KAN}({\\bf x})={\\bf \\Phi}_{L-1}\\circ\\cdots \\circ{\\bf \\Phi}_1\\circ{\\bf \\Phi}_0\\circ {\\bf x}$$\n",
    "\n",
    "相比之下，多层感知机（Multi-Layer Perceptron）是由线性层 ${\\bf W}_l$ 和非线性函数 $\\sigma$ 交错组成的：\n",
    "\n",
    "$${\\rm MLP}({\\bf x})={\\bf W}_{L-1}\\circ\\sigma\\circ\\cdots\\circ {\\bf W}_1\\circ\\sigma\\circ {\\bf W}_0\\circ {\\bf x}$$\n",
    "\n",
    "科尔莫戈洛夫-阿诺尔德网络（KAN）可以很容易地进行可视化。\n",
    "(1) KAN只是一系列KAN层的堆叠。\n",
    "(2) 每个KAN层可以被视为一个全连接层，其中每条边上放置了一个一维函数。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a83ba198534027a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 实现 KAN 网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1829133c4f70f897"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### spline.py\n",
    "由于KAN网络使用spline b样条函数作为激活函数，那么首先实现spline样条函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67a9a29bbf22bf9d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def B_batch(x, grid, k=0, extend=True, device='cpu'):\n",
    "    '''\n",
    "    在B样条基上评估x的值\n",
    "    参数:\n",
    "    -----\n",
    "        x : 2D torch.tensor\n",
    "            输入，形状为(样条数, 样本数)\n",
    "        grid : 2D torch.tensor\n",
    "            网格，形状为(样条数, 网格点数)\n",
    "        k : int\n",
    "            样条的分段多项式的阶数。\n",
    "        extend : bool\n",
    "            如果为True，在两端扩展k点。如果为False，不扩展（零边界条件）。默认为True\n",
    "        device : str\n",
    "            设备\n",
    "    '''\n",
    "    \n",
    "    # x形状: (size, x); grid形状: (size, grid)\n",
    "    def extend_grid(grid, k_extend=0):\n",
    "        # 向左和向右补充k\n",
    "        # grid形状: (批量, 网格)\n",
    "        h = (grid[:, [-1]] - grid[:, [0]]) / (grid.shape[1] - 1)\n",
    "        \n",
    "        for i in range(k_extend):\n",
    "            grid = torch.cat([grid[:, [0]] - h, grid], dim=1)\n",
    "            grid = torch.cat([grid, grid[:, [-1]] + h], dim=1)\n",
    "        grid = grid.to(device)\n",
    "        return grid\n",
    "    \n",
    "    if extend == True:\n",
    "        grid = extend_grid(grid, k_extend=k)\n",
    "    \n",
    "    grid = grid.unsqueeze(dim=2).to(device)\n",
    "    x = x.unsqueeze(dim=1).to(device)\n",
    "    \n",
    "    if k == 0:\n",
    "        value = (x >= grid[:, :-1]) * (x < grid[:, 1:])\n",
    "    else:\n",
    "        B_km1 = B_batch(x[:, 0], grid=grid[:, :, 0], k=k - 1, extend=False, device=device)\n",
    "        value = (x - grid[:, :-(k + 1)]) / (grid[:, k:-1] - grid[:, :-(k + 1)]) * B_km1[:, :-1] + (\n",
    "                    grid[:, k + 1:] - x) / (grid[:, k + 1:] - grid[:, 1:(-k)]) * B_km1[:, 1:]\n",
    "    return value\n",
    "\n",
    "def coef2curve(x_eval, grid, coef, k, device=\"cpu\"):\n",
    "    '''\n",
    "    将B样条系数转换为B样条曲线。对B样条曲线上的x进行评估（将B_batch结果沿B样条基相加）。\n",
    "\n",
    "    参数:\n",
    "    -----\n",
    "        x_eval : 2D torch.tensor\n",
    "            形状为(样条数, 样本数)\n",
    "        grid : 2D torch.tensor\n",
    "            形状为(样条数, 网格点数)\n",
    "        coef : 2D torch.tensor\n",
    "            形状为(样条数, 系数参数数)。系数参数数 = 网格间隔数 + k\n",
    "        k : int\n",
    "            样条的分段多项式的阶数。\n",
    "        device : str\n",
    "            设备\n",
    "\n",
    "    '''\n",
    "    # x_eval: (size, batch), grid: (size, grid), coef: (size, coef)\n",
    "    # coef: (size, coef), B_batch: (size, coef, batch), 对coef求和\n",
    "    if coef.dtype != x_eval.dtype:\n",
    "        coef = coef.to(x_eval.dtype)\n",
    "    y_eval = torch.einsum('ij,ijk->ik', coef, B_batch(x_eval, grid, k, device=device))\n",
    "    return y_eval\n",
    "\n",
    "def curve2coef(x_eval, y_eval, grid, k, device=\"cpu\"):\n",
    "    '''\n",
    "    使用最小二乘法将B样条曲线转换为B样条系数。\n",
    "    参数:\n",
    "    -----\n",
    "        x_eval : 2D torch.tensor\n",
    "            形状为(样条数, 样本数)\n",
    "        y_eval : 2D torch.tensor\n",
    "            形状为(样条数, 样本数)\n",
    "        grid : 2D torch.tensor\n",
    "            形状为(样条数, 网格点数)\n",
    "        k : int\n",
    "            样条的分段多项式的阶数。\n",
    "        device : str\n",
    "            设备\n",
    "\n",
    "    '''\n",
    "    # x_eval: (size, batch); y_eval: (size, batch); grid: (size, grid); k: 标量\n",
    "    mat = B_batch(x_eval, grid, k, device=device).permute(0, 2, 1)\n",
    "    # 使用不同的算法解决最小二乘问题根据设备类型选择\n",
    "    coef = torch.linalg.lstsq(mat.to(device), y_eval.unsqueeze(dim=2).to(device),\n",
    "                              driver='gelsy' if device == 'cpu' else 'gels').solution[:, :, 0]\n",
    "    return coef.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.524600Z",
     "start_time": "2024-05-20T09:17:36.278907Z"
    }
   },
   "id": "89f5f941b2ae9ec1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KANLayer.py\n",
    "定义了KAN模型中使用的自定义层，包括模型的核心组件，如特殊的激活层或其他处理层，这些是构成KAN的基础。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874d2babfed8a8c1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class KANLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    KANLayer 类\n",
    "    属性:\n",
    "    ----\n",
    "        in_dim: int\n",
    "            输入维度\n",
    "        out_dim: int\n",
    "            输出维度\n",
    "        size: int\n",
    "            样条曲线的数量 = 输入维度 * 输出维度\n",
    "        k: int\n",
    "            样条的分段多项式阶数\n",
    "        grid: 2D torch.float\n",
    "            网格点\n",
    "        noises: 2D torch.float\n",
    "            初始化时注入的噪声以打破退化(degeneracy)\n",
    "        coef: 2D torch.tensor\n",
    "            B样条基的系数\n",
    "        scale_base: 1D torch.float\n",
    "            残差函数b(x)的幅度\n",
    "        scale_sp: 1D torch.float\n",
    "            样条函数spline(x)的幅度\n",
    "        base_fun: fun\n",
    "            残差函数b(x)\n",
    "        mask: 1D torch.float\n",
    "            样条函数的掩码。将掩码的某些元素设置为零意味着将相应的激活设置为零函数。\n",
    "        grid_eps: float in [0,1]\n",
    "            用于基于样本的激活更新网格的超参数。当grid_eps = 0时，网格是均匀的；当grid_eps = 1时，网格使用样本的百分位数进行划分。0 < grid_eps < 1在两个极端之间插值。\n",
    "        weight_sharing: 1D tensor int\n",
    "            允许样条激活共享参数\n",
    "        lock_counter: int\n",
    "            记录多少个激活函数被锁定（参数共享）\n",
    "        lock_id: 1D torch.int\n",
    "            被锁定激活函数的id\n",
    "        device: str\n",
    "            设备\n",
    "\n",
    "    方法:\n",
    "    -----\n",
    "        __init__():\n",
    "            初始化KANLayer\n",
    "        forward():\n",
    "            前向传播\n",
    "        update_grid_from_samples():\n",
    "            基于样本的激活更新网格\n",
    "        initialize_grid_from_parent():\n",
    "            从另一个模型初始化网格\n",
    "        get_subset():\n",
    "            获取KANLayer的子集（用于剪枝）\n",
    "        lock():\n",
    "            锁定几个激活函数以共享参数\n",
    "        unlock():\n",
    "            解锁已经锁定的激活函数\n",
    "    \"\"\" \n",
    "    def __init__(self, in_dim=3, out_dim=2, num=5, k=3, noise_scale=0.1, \n",
    "                 scale_base=1.0, scale_sp=1.0, \n",
    "                 base_fun=torch.nn.SiLU(), grid_eps=0.02, grid_range=[-1, 1], \n",
    "                 sp_trainable=True, \n",
    "                 sb_trainable=True, device='cpu'):\n",
    "        '''初始化一个KANLayer\n",
    "        参数：\n",
    "        -----\n",
    "            in_dim : int\n",
    "                输入维度。默认值：2。\n",
    "            out_dim : int\n",
    "                输出维度。默认值：3。\n",
    "            num : int\n",
    "                网格间隔的数量 = G。默认值：5。\n",
    "            k : int\n",
    "                分段多项式的阶数。默认值：3。\n",
    "            noise_scale : float\n",
    "                初始化时注入的噪声的尺度。默认值：0.1。\n",
    "            scale_base : float\n",
    "                残差函数 b(x) 的尺度。默认值：1.0。\n",
    "            scale_sp : float\n",
    "                基础函数 spline(x) 的尺度。默认值：1.0。\n",
    "            base_fun : function\n",
    "                残差函数 b(x)。默认值：torch.nn.SiLU()\n",
    "            grid_eps : float\n",
    "                当 grid_eps = 0 时，网格是均匀分布的；当 grid_eps = 1 时，网格使用样本的百分位数进行划分。0 < grid_eps < 1 在两个极端之间插值。默认值：0.02。\n",
    "            grid_range : list/np.array of shape (2,)\n",
    "                设置网格的范围。默认值：[-1,1]。\n",
    "            sp_trainable : bool\n",
    "                如果为True，则scale_sp可训练。默认值：True。\n",
    "            sb_trainable : bool\n",
    "                如果为True，则scale_base可训练。默认值：True。\n",
    "            device : str\n",
    "                设备\n",
    "        '''\n",
    "        super(KANLayer, self).__init__()\n",
    "        # size \n",
    "        self.size = size = out_dim * in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.num = num\n",
    "        self.k = k\n",
    "        \n",
    "        # shape: (size, num)\n",
    "        self.grid = torch.einsum('i,j->ij', torch.ones(size, device=device), torch.linspace(grid_range[0], grid_range[1], steps=num + 1, device=device))\n",
    "        self.grid = torch.nn.Parameter(self.grid).requires_grad_(False)\n",
    "        noises = (torch.rand(size, self.grid.shape[1]) - 1 / 2) * noise_scale / num\n",
    "        noises = noises.to(device)\n",
    "        # shape: (size, coef)\n",
    "        self.coef = torch.nn.Parameter(curve2coef(self.grid, noises, self.grid, k, device))\n",
    "        if isinstance(scale_base, float):\n",
    "            self.scale_base = torch.nn.Parameter(torch.ones(size, device=device) * scale_base).requires_grad_(sb_trainable)  # make scale trainable\n",
    "        else:\n",
    "            self.scale_base = torch.nn.Parameter(torch.DoubleTensor(scale_base).to(device)).requires_grad_(sb_trainable)\n",
    "        self.scale_sp = torch.nn.Parameter(torch.ones(size, device=device) * scale_sp).requires_grad_(sp_trainable)  # make scale trainable\n",
    "        self.base_fun = base_fun\n",
    "    \n",
    "        self.mask = torch.nn.Parameter(torch.ones(size, device=device)).requires_grad_(False)\n",
    "        self.grid_eps = grid_eps\n",
    "        self.weight_sharing = torch.arange(size)\n",
    "        self.lock_counter = 0\n",
    "        self.lock_id = torch.zeros(size)\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        KANLayer根据输入x进行前向传播\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            x : 2D torch.float\n",
    "                输入数据，形状为 (样本数, 输入维度)\n",
    "        \n",
    "        返回:\n",
    "        --------\n",
    "            y : 2D torch.float\n",
    "                输出数据，形状为 (样本数, 输出维度)\n",
    "            preacts : 3D torch.float\n",
    "                将x展开到激活函数的激活值，形状为 (样本数, 输出维度, 输入维度)\n",
    "            postacts : 3D torch.float\n",
    "                激活函数输出值，以preacts为输入\n",
    "            postspline : 3D torch.float\n",
    "                样条函数输出值，以preacts为输入\n",
    "        \"\"\"\n",
    "        batch = x.shape[0]\n",
    "        # x形状: (批次数, 输入维度) => 形状 (大小, 批次数) (大小 = 输出维度 * 输入维度)\n",
    "        x = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, device=self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        preacts = x.permute(1, 0).clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        base = self.base_fun(x).permute(1, 0)  # 形状 (批次数, 大小)\n",
    "        # 使用样条转换函数coef2curve计算输出y，形状(size, 批次数)\n",
    "        y = coef2curve(x_eval=x, grid=self.grid[self.weight_sharing], coef=self.coef[self.weight_sharing], k=self.k, device=self.device)\n",
    "        y = y.permute(1, 0)  # 形状 (批次数, 大小)\n",
    "        postspline = y.clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        # 结果y通过应用缩放因子和遮罩进行调整\n",
    "        y = self.scale_base.unsqueeze(dim=0) * base + self.scale_sp.unsqueeze(dim=0) * y\n",
    "        y = self.mask[None, :] * y\n",
    "        postacts = y.clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        y = torch.sum(y.reshape(batch, self.out_dim, self.in_dim), dim=2)  # 形状 (批次数, 输出维度)\n",
    "        \n",
    "        # 返回结果\n",
    "        return y, preacts, postacts, postspline\n",
    "        \n",
    "    def update_grid_from_samples(self, x):\n",
    "        \"\"\"\n",
    "        根据样本更新网格\n",
    "        \n",
    "        参数:\n",
    "        ----\n",
    "        x : 2D torch.float\n",
    "            输入，形状为(样本数量, 输入维度)\n",
    "        \"\"\"\n",
    "        batch = x.shape[0]\n",
    "        x = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, ).to(self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        x_pos = torch.sort(x, dim=1)[0]\n",
    "        y_eval = coef2curve(x_pos, self.grid, self.coef, self.k, device=self.device)\n",
    "        num_interval = self.grid.shape[1] - 1\n",
    "        ids = [int(batch / num_interval * i) for i in range(num_interval)] + [-1]\n",
    "        grid_adaptive = x_pos[:, ids]\n",
    "        margin = 0.01\n",
    "        grid_uniform = torch.cat([grid_adaptive[:, [0]] - margin + (grid_adaptive[:, [-1]] - grid_adaptive[:, [0]] + 2 * margin) * a for a in np.linspace(0, 1, num=self.grid.shape[1])], dim=1)\n",
    "        self.grid.data = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "        self.coef.data = curve2coef(x_pos, y_eval, self.grid, self.k, device=self.device)\n",
    "        \n",
    "    def initialize_grid_from_parent(self, parent, x):\n",
    "        '''\n",
    "        从父KANLayer和样本中更新网格\n",
    "        \n",
    "        参数:\n",
    "        ------\n",
    "            parent : KANLayer\n",
    "                父KANLayer（其网格通常比当前模型粗）\n",
    "            x : 2D torch.float\n",
    "                输入样本，形状为（样本数量，输入维度）\n",
    "        '''\n",
    "        batch = x.shape[0]\n",
    "        # preacts: 形状为 (batch, in_dim) => 形状为 (size, batch) (size = out_dim * in_dim)\n",
    "        x_eval = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, ).to(self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        x_pos = parent.grid\n",
    "        sp2 = KANLayer(in_dim=1, out_dim=self.size, k=1, num=x_pos.shape[1] - 1, scale_base=0., device=self.device)\n",
    "        sp2.coef.data = curve2coef(sp2.grid, x_pos, sp2.grid, k=1, device=self.device)\n",
    "        y_eval = coef2curve(x_eval, parent.grid, parent.coef, parent.k, device=self.device)\n",
    "        percentile = torch.linspace(-1, 1, self.num + 1).to(self.device)\n",
    "        self.grid.data = sp2(percentile.unsqueeze(dim=1))[0].permute(1, 0)\n",
    "        self.coef.data = curve2coef(x_eval, y_eval, self.grid, self.k, self.device)\n",
    "                \n",
    "    def get_subset(self, in_id, out_id):\n",
    "        '''\n",
    "        从较大的KANLayer中获取一个较小的KANLayer（用于剪枝），以减少网络的复杂性或者提高计入的效率\n",
    "        \n",
    "        参数:\n",
    "        ------\n",
    "            in_id : list\n",
    "                选择的输入神经元的ID列表\n",
    "            out_id : list\n",
    "                选择的输出神经元的ID列表\n",
    "            \n",
    "        返回:\n",
    "        ------\n",
    "            spb : KANLayer\n",
    "        '''\n",
    "        spb = KANLayer(len(in_id), len(out_id), self.num, self.k, base_fun=self.base_fun, device=self.device)\n",
    "        spb.grid.data = self.grid.reshape(self.out_dim, self.in_dim, spb.num + 1)[out_id][:, in_id].reshape(-1, spb.num + 1)\n",
    "        spb.coef.data = self.coef.reshape(self.out_dim, self.in_dim, spb.coef.shape[1])[out_id][:, in_id].reshape(-1, spb.coef.shape[1])\n",
    "        spb.scale_base.data = self.scale_base.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "        spb.scale_sp.data = self.scale_sp.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "        spb.mask.data = self.mask.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "\n",
    "        spb.in_dim = len(in_id)\n",
    "        spb.out_dim = len(out_id)\n",
    "        spb.size = spb.in_dim * spb.out_dim\n",
    "        return spb\n",
    "            \n",
    "    def lock(self, ids):\n",
    "        '''\n",
    "        根据 ids 锁定激活函数以共享参数\n",
    "    \n",
    "        参数:\n",
    "        -----\n",
    "            ids : list\n",
    "                激活函数的 id 列表\n",
    "        '''\n",
    "        self.lock_counter += 1\n",
    "        # ids: [[i1,j1],[i2,j2],[i3,j3],...]\n",
    "        for i in range(len(ids)):\n",
    "            if i != 0:\n",
    "                # 根据第一个 id 更改其他id对应的激活函数的参数共享指向\n",
    "                self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] = ids[0][1] * self.in_dim + ids[0][0]\n",
    "            # 为每个 id 分配锁定计数器，用于后续的参数共享判断\n",
    "            self.lock_id[ids[i][1] * self.in_dim + ids[i][0]] = self.lock_counter\n",
    "            \n",
    "    def unlock(self, ids):\n",
    "        '''\n",
    "        解锁激活函数\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            ids : list\n",
    "                激活函数的id列表\n",
    "                 [6, 7, 8]])\n",
    "        '''\n",
    "        # 检查 ids 是否已锁定\n",
    "        num = len(ids)\n",
    "        locked = True\n",
    "        for i in range(num):\n",
    "            locked *= (self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] == self.weight_sharing[ids[0][1] * self.in_dim + ids[0][0]])\n",
    "        if locked == False:\n",
    "            print(\"这些激活函数没有锁定。解锁失败。\")\n",
    "            return 0\n",
    "        for i in range(len(ids)):\n",
    "            # 将权重共享索引重置为默认状态\n",
    "            self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] = ids[i][1] * self.in_dim + ids[i][0]\n",
    "            # 重置锁定标识\n",
    "            self.lock_id[ids[i][1] * self.in_dim + ids[i][0]] = 0\n",
    "        # 减少锁定计数器\n",
    "        self.lock_counter -= 1\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.545243300Z",
     "start_time": "2024-05-20T09:17:36.309118500Z"
    }
   },
   "id": "89f8156e8c98d00b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### utils.py\n",
    "数学和符号计算框架"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c47e3d6f7ada1309"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 初始化一些符号库\n",
    "SYMBOLIC_LIB = {\n",
    "    'x': (lambda x: x, lambda x: x),\n",
    "    'x^2': (lambda x: x**2, lambda x: x**2),\n",
    "    'x^3': (lambda x: x**3, lambda x: x**3),\n",
    "    'x^4': (lambda x: x**4, lambda x: x**4),\n",
    "    '1/x': (lambda x: 1/x, lambda x: 1/x),\n",
    "    '1/x^2': (lambda x: 1/x**2, lambda x: 1/x**2),\n",
    "    '1/x^3': (lambda x: 1/x**3, lambda x: 1/x**3),\n",
    "    '1/x^4': (lambda x: 1/x**4, lambda x: 1/x**4),\n",
    "    'sqrt': (lambda x: torch.sqrt(x), lambda x: sympy.sqrt(x)),\n",
    "    '1/sqrt(x)': (lambda x: 1/torch.sqrt(x), lambda x: 1/sympy.sqrt(x)),\n",
    "    'exp': (lambda x: torch.exp(x), lambda x: sympy.exp(x)),\n",
    "    'log': (lambda x: torch.log(x), lambda x: sympy.log(x)),\n",
    "    'abs': (lambda x: torch.abs(x), lambda x: sympy.Abs(x)),\n",
    "    'sin': (lambda x: torch.sin(x), lambda x: sympy.sin(x)),\n",
    "    'tan': (lambda x: torch.tan(x), lambda x: sympy.tan(x)),\n",
    "    'tanh': (lambda x: torch.tanh(x), lambda x: sympy.tanh(x)),\n",
    "    'sigmoid': (lambda x: torch.sigmoid(x), sympy.Function('sigmoid')),\n",
    "    'sgn': (lambda x: torch.sign(x), lambda x: sympy.sign(x)),\n",
    "    'arcsin': (lambda x: torch.arcsin(x), lambda x: sympy.arcsin(x)),\n",
    "    'arctan': (lambda x: torch.arctan(x), lambda x: sympy.atan(x)),\n",
    "    'arctanh': (lambda x: torch.arctanh(x), lambda x: sympy.atanh(x)),\n",
    "    '0': (lambda x: x*0, lambda x: x*0),\n",
    "    'gaussian': (lambda x: torch.exp(-x**2), lambda x: sympy.exp(-x**2)),\n",
    "    'cosh': (lambda x: torch.cosh(x), lambda x: sympy.cosh(x)),\n",
    "}\n",
    "\n",
    "def create_dataset(f, \n",
    "                   n_var=2, \n",
    "                   ranges = [-1,1],\n",
    "                   train_num=1000, \n",
    "                   test_num=1000,\n",
    "                   normalize_input=False,\n",
    "                   normalize_label=False,\n",
    "                   device='cpu',\n",
    "                   seed=0):\n",
    "    '''\n",
    "    创建数据集\n",
    "    \n",
    "    参数:\n",
    "    -----\n",
    "        f : function\n",
    "            创建合成数据集所使用的符号公式\n",
    "        ranges : list or np.array; shape (2,) or (n_var, 2)\n",
    "            输入变量的范围，默认为 [-1,1]。\n",
    "        train_num : int\n",
    "            训练样本数量，默认为 1000。\n",
    "        test_num : int\n",
    "            测试样本数量，默认为 1000。\n",
    "        normalize_input : bool\n",
    "            如果为 True，则对输入应用标准化，默认为 False。\n",
    "        normalize_label : bool\n",
    "            如果为 True，则对标签应用标准化，默认为 False。\n",
    "        device : str\n",
    "            设备，默认为 'cpu'。\n",
    "        seed : int\n",
    "            随机种子，默认为 0。\n",
    "\n",
    "    返回:\n",
    "    --------\n",
    "        dataset : dic\n",
    "            Train/test inputs/labels are dataset['train_input'], dataset['train_label'],\n",
    "                        dataset['test_input'], dataset['test_label']\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if len(np.array(ranges).shape) == 1:\n",
    "        ranges = np.array(ranges * n_var).reshape(n_var, 2)\n",
    "    else:\n",
    "        ranges = np.array(ranges)\n",
    "        \n",
    "    train_input = torch.zeros(train_num, n_var)\n",
    "    test_input = torch.zeros(test_num, n_var)\n",
    "    for i in range(n_var):\n",
    "        train_input[:, i] = torch.rand(train_num,) * (ranges[i, 1] - ranges[i, 0]) + ranges[i, 0]\n",
    "        test_input[:, i] = torch.rand(test_num,) * (ranges[i, 1] - ranges[i, 0]) + ranges[i, 0]\n",
    "                  \n",
    "    train_label = f(train_input)\n",
    "    test_label = f(test_input)\n",
    "                  \n",
    "    def normalize(data, mean, std):\n",
    "        '''\n",
    "        将数据标准化\n",
    "\n",
    "        参数:\n",
    "        -----\n",
    "            data : 数据\n",
    "            mean : 均值\n",
    "            std : 标准差\n",
    "\n",
    "        返回:\n",
    "        ------\n",
    "            标准化后的数据\n",
    "        '''\n",
    "        return (data - mean) / std\n",
    "                 \n",
    "    if normalize_input == True:\n",
    "        mean_input = torch.mean(train_input, dim=0, keepdim=True)\n",
    "        std_input = torch.std(train_input, dim=0, keepdim=True)\n",
    "        train_input = normalize(train_input, mean_input, std_input)\n",
    "        test_input = normalize(test_input, mean_input, std_input)\n",
    "                 \n",
    "    if normalize_label == True:\n",
    "        mean_label = torch.mean(train_label, dim=0, keepdim=True)\n",
    "        std_label = torch.std(train_label, dim=0, keepdim=True)\n",
    "        train_label = normalize(train_label, mean_label, std_label)\n",
    "        test_label = normalize(test_label, mean_label, std_label)\n",
    " \n",
    "    dataset = {\n",
    "        'train_input': train_input.to(device),\n",
    "        'test_input': test_input.to(device),\n",
    "        'train_label': train_label.to(device),\n",
    "        'test_label': test_label.to(device),\n",
    "    }\n",
    " \n",
    "    return dataset\n",
    "def fit_params(x, y, fun, a_range=(-10,10), b_range=(-10,10), grid_number=101, iteration=3, verbose=True, device='cpu'):\n",
    "    '''\n",
    "    根据给定函数 fun 调整参数 a, b, c, d ，使得以下公式最小化：\n",
    "          .. math::\n",
    "         |y-(cf(ax+b)+d)|^2\n",
    "    其中 x 和 y 都是一维数组。沿 a 和 b 进行扫描，找到最佳拟合的模型。\n",
    "          参数:\n",
    "    -----\n",
    "         x : 1D array\n",
    "             x 的值\n",
    "         y : 1D array\n",
    "             y 的值\n",
    "         fun : function\n",
    "             符号函数\n",
    "         a_range : tuple\n",
    "             a 的扫描范围\n",
    "         b_range : tuple\n",
    "             b 的扫描范围\n",
    "         grid_num : int\n",
    "             a 和 b 沿其范围内的步数\n",
    "         iteration : int\n",
    "             放大倍数\n",
    "         verbose : bool\n",
    "             如果为 True，则打印额外信息\n",
    "         device : str\n",
    "             设备\n",
    "          返回值:\n",
    "    --------\n",
    "         a_best : float\n",
    "             最佳拟合 a 的值\n",
    "         b_best : float\n",
    "             最佳拟合 b 的值\n",
    "         c_best : float\n",
    "             最佳拟合 c 的值\n",
    "         d_best : float\n",
    "             最佳拟合 d 的值\n",
    "         r2_best : float\n",
    "             最佳 r2 值（决定系数）\n",
    "          示例\n",
    "    -------\n",
    "     >>> num = 100\n",
    "     >>> x = torch.linspace(-1,1,steps=num)\n",
    "     >>> noises = torch.normal(0,1,(num,)) * 0.02\n",
    "     >>> y = 5.0*torch.sin(3.0*x + 2.0) + 0.7 + noises\n",
    "     >>> fit_params(x, y, torch.sin)\n",
    "     r2 为 0.9999727010726929\n",
    "     (tensor([2.9982, 1.9996, 5.0053, 0.7011]), tensor(1.0000))\n",
    "    '''\n",
    "    \n",
    "    for _ in range(iteration):\n",
    "        a_ = torch.linspace(a_range[0], a_range[1], steps=grid_number, device=device)\n",
    "        b_ = torch.linspace(b_range[0], b_range[1], steps=grid_number, device=device)\n",
    "        a_grid, b_grid = torch.meshgrid(a_, b_, indexing='ij')\n",
    "        post_fun = fun(a_grid[None,:,:] * x[:,None,None] + b_grid[None,:,:])\n",
    "        x_mean = torch.mean(post_fun, dim=[0], keepdim=True)\n",
    "        y_mean = torch.mean(y, dim=[0], keepdim=True)\n",
    "        numerator = torch.sum((post_fun - x_mean)*(y-y_mean)[:,None,None], dim=0)**2\n",
    "        denominator = torch.sum((post_fun - x_mean)**2, dim=0)*torch.sum((y - y_mean)[:,None,None]**2, dim=0)\n",
    "        r2 = numerator / (denominator + 1e-4)\n",
    "        r2 = torch.nan_to_num(r2)\n",
    "\n",
    "        best_id = torch.argmax(r2)\n",
    "        a_id, b_id = torch.div(best_id, grid_number, rounding_mode='floor'), best_id % grid_number\n",
    "\n",
    "        if a_id == 0 or a_id == grid_number - 1 or b_id == 0 or b_id == grid_number - 1:\n",
    "            if _ == 0 and verbose == True:\n",
    "                print('最佳值位于边界。')\n",
    "            if a_id == 0:\n",
    "                a_arange = [a_[0], a_[1]]\n",
    "            if a_id == grid_number - 1:\n",
    "                a_arange = [a_[-2], a_[-1]]\n",
    "            if b_id == 0:\n",
    "                b_arange = [b_[0], b_[1]]\n",
    "            if b_id == grid_number - 1:\n",
    "                b_arange = [b_[-2], b_[-1]]\n",
    "\n",
    "        else:\n",
    "            a_range = [a_[a_id-1], a_[a_id+1]]\n",
    "            b_range = [b_[b_id-1], b_[b_id+1]]\n",
    "\n",
    "    a_best = a_[a_id]\n",
    "    b_best = b_[b_id]\n",
    "    post_fun = fun(a_best * x + b_best)\n",
    "    r2_best = r2[a_id, b_id]\n",
    "\n",
    "    if verbose == True:\n",
    "        print(f\"r2 为 {r2_best}\")\n",
    "        if r2_best < 0.9:\n",
    "            print(f'r2 值不是很高，请检查你是否选择了正确的符号函数。')\n",
    "\n",
    "    post_fun = torch.nan_to_num(post_fun)\n",
    "    reg = LinearRegression().fit(post_fun[:, None].detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "    c_best = torch.from_numpy(reg.coef_)[0].to(device)\n",
    "    d_best = torch.from_numpy(np.array(reg.intercept_)).to(device)\n",
    "    return torch.stack([a_best, b_best, c_best, d_best]), r2_best\n",
    "\n",
    "def add_symbolic(name, fun):\n",
    "    '''\n",
    "    向库中添加符号函数\n",
    "    \n",
    "    参数:\n",
    "    -----\n",
    "        name : str\n",
    "            函数名称\n",
    "        fun : fun\n",
    "            Torch函数或lambda函数\n",
    "    '''\n",
    "    exec(f\"globals()['{name}'] = sympy.Function('{name}')\")\n",
    "    SYMBOLIC_LIB[name] = (fun, globals()[name])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.570264700Z",
     "start_time": "2024-05-20T09:17:36.337656200Z"
    }
   },
   "id": "3c10eb0997de2530"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Symbolic_KANLayer.py\n",
    "实现了一种特殊的KAN层，用于处理符号计算或增强模型的解释性。将数据或激活函数转换为符号形式，以便进行更深入的分析或解释。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7db849f68d30839"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sympy\n",
    "\n",
    "class Symbolic_KANLayer(nn.Module):\n",
    "    '''\n",
    "    KANLayer 类\n",
    "\n",
    "    属性:\n",
    "    -------\n",
    "        in_dim: int\n",
    "            输入维度\n",
    "        out_dim: int\n",
    "            输出维度\n",
    "        funs: 2D 数组，元素为 torch 函数或 lambda 函数\n",
    "            符号函数（torch）\n",
    "        funs_name: 2D 数组，元素为字符串\n",
    "            符号函数的名称\n",
    "        funs_sympy: 2D 数组，元素为 sympy 函数或 lambda 函数\n",
    "            符号函数（sympy）\n",
    "        affine: 3D 浮点数组\n",
    "            输入和输出的仿射变换参数\n",
    "\n",
    "    方法:\n",
    "    -------\n",
    "        __init__():\n",
    "            初始化 Symbolic_KANLayer\n",
    "        forward():\n",
    "            前向计算方法\n",
    "        get_subset():\n",
    "            获取 KANLayer 的子集（用于剪枝）\n",
    "        fix_symbolic():\n",
    "            将激活函数固定为符号函数\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_dim=3, out_dim=2, device='cpu'):\n",
    "        '''\n",
    "        初始化 Symbolic_KANLayer（激活函数初始化为恒等函数）\n",
    "\n",
    "        参数:\n",
    "        -----\n",
    "            in_dim : int\n",
    "                输入维度\n",
    "            out_dim : int\n",
    "                输出维度\n",
    "            device : str\n",
    "                设备\n",
    "\n",
    "        返回:\n",
    "        --------\n",
    "            self\n",
    "\n",
    "        '''\n",
    "        super(Symbolic_KANLayer, self).__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.mask = torch.nn.Parameter(torch.zeros(out_dim, in_dim, device=device)).requires_grad_(False)\n",
    "        # torch\n",
    "        self.funs = [[lambda x: x for i in range(self.in_dim)] for j in range(self.out_dim)]\n",
    "        # name\n",
    "        self.funs_name = [['' for i in range(self.in_dim)] for j in range(self.out_dim)]\n",
    "        # sympy\n",
    "        self.funs_sympy = [['' for i in range(self.in_dim)] for j in range(self.out_dim)]\n",
    "\n",
    "        self.affine = torch.nn.Parameter(torch.zeros(out_dim, in_dim, 4, device=device))\n",
    "        # c*f(a*x+b)+d\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        前向计算方法\n",
    "\n",
    "        参数:\n",
    "        -----\n",
    "            x : 2D 数组\n",
    "                输入，形状 (batch, 输入维度)\n",
    "\n",
    "        返回:\n",
    "        --------\n",
    "            y : 2D 数组\n",
    "                输出，形状 (batch, 输出维度)\n",
    "            postacts : 3D 数组\n",
    "                激活函数之后但在节点上求和之前的激活值\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        batch = x.shape[0]\n",
    "        postacts = []\n",
    "\n",
    "        for i in range(self.in_dim):\n",
    "            postacts_ = []\n",
    "            for j in range(self.out_dim):\n",
    "                xij = self.affine[j,i,2]*self.funs[j][i](self.affine[j,i,0]*x[:,[i]]+self.affine[j,i,1])+self.affine[j,i,3]\n",
    "                postacts_.append(self.mask[j][i]*xij)\n",
    "            postacts.append(torch.stack(postacts_))\n",
    "\n",
    "        postacts = torch.stack(postacts)\n",
    "        postacts = postacts.permute(2,1,0,3)[:,:,:,0]\n",
    "        y = torch.sum(postacts, dim=2)\n",
    "\n",
    "        return y, postacts\n",
    "    \n",
    "    def get_subset(self, in_id, out_id):\n",
    "        '''\n",
    "        从一个更大的 Symbolic_KANLayer 中获取一个更小的 Symbolic_KANLayer（用于修剪）\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            in_id : list\n",
    "                选定输入神经元的 id\n",
    "            out_id : list\n",
    "                选定输出神经元的 id\n",
    "                 \n",
    "        返回值:\n",
    "        --------\n",
    "            spb : Symbolic_KANLayer\n",
    "        \n",
    "        '''\n",
    "        sbb = Symbolic_KANLayer(self.in_dim, self.out_dim, device=self.device)\n",
    "        sbb.in_dim = len(in_id)\n",
    "        sbb.out_dim = len(out_id)\n",
    "        sbb.mask.data = self.mask.data[out_id][:,in_id]\n",
    "        sbb.funs = [[self.funs[j][i] for i in in_id] for j in out_id]\n",
    "        sbb.funs_sympy = [[self.funs_sympy[j][i] for i in in_id] for j in out_id]\n",
    "        sbb.funs_name = [[self.funs_name[j][i] for i in in_id] for j in out_id]\n",
    "        sbb.affine.data = self.affine.data[out_id][:,in_id]\n",
    "        return sbb\n",
    "\n",
    "    def fix_symbolic(self, i, j, fun_name, x=None, y=None, random=False, a_range=(-10,10), b_range=(-10,10), verbose=True):\n",
    "        '''\n",
    "        将激活函数固定为符号函数\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            i : int\n",
    "                输入神经元的 id\n",
    "            j : int\n",
    "                输出神经元的 id\n",
    "            fun_name : str\n",
    "                符号函数的名称\n",
    "            x : 1D array\n",
    "                预激活值\n",
    "            y : 1D array\n",
    "                后激活值\n",
    "            a_range : tuple\n",
    "                a 的扫描范围\n",
    "            b_range : tuple\n",
    "                a 的扫描范围\n",
    "            verbose : bool\n",
    "                若为 True，则打印更多信息\n",
    "                \n",
    "        返回值:\n",
    "        --------\n",
    "            r2（决定系数）\n",
    "    \n",
    "        '''\n",
    "        if isinstance(fun_name,str):\n",
    "            fun = SYMBOLIC_LIB[fun_name][0]\n",
    "            fun_sympy = SYMBOLIC_LIB[fun_name][1]\n",
    "            self.funs_sympy[j][i] = fun_sympy\n",
    "            self.funs_name[j][i] = fun_name\n",
    "            if x == None or y == None:\n",
    "                # 仅从函数初始化\n",
    "                self.funs[j][i] = fun\n",
    "                if random == False:\n",
    "                    self.affine.data[j][i] = torch.tensor([1.,0.,1.,0.])\n",
    "                else:\n",
    "                    self.affine.data[j][i] = torch.rand(4,) * 2 - 1\n",
    "                return None\n",
    "            else:\n",
    "                # 根据 x & y 和函数初始化\n",
    "                params, r2 = fit_params(x, y, fun, a_range=a_range, b_range=b_range, verbose=verbose, device=self.device)\n",
    "                self.funs[j][i] = fun\n",
    "                self.affine.data[j][i] = params\n",
    "                return r2\n",
    "        else:\n",
    "            # 如果 fun_name 本身就是一个函数\n",
    "            fun = fun_name\n",
    "            fun_sympy = fun_name\n",
    "            self.funs_sympy[j][i] = fun_sympy\n",
    "            self.funs_name[j][i] = \"匿名\"\n",
    "            \n",
    "            self.funs[j][i] = fun\n",
    "            if random == False:\n",
    "                self.affine.data[j][i] = torch.tensor([1.,0.,1.,0.])\n",
    "            else:\n",
    "                self.affine.data[j][i] = torch.rand(4,) * 2 - 1\n",
    "            return None\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.593284800Z",
     "start_time": "2024-05-20T09:17:36.363472100Z"
    }
   },
   "id": "22ae1406e46ad78d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBFGS.py\n",
    "包含了适用于KANs训练的L-BFGS优化器的实现"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a528fb364b5f428"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import reduce\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "__all__ = ['LBFGS']\n",
    "\n",
    "def _cubic_interpolate(x1, f1, g1, x2, f2, g2, bounds=None):\n",
    "    # ported from https://github.com/torch/optim/blob/master/polyinterp.lua\n",
    "    # Compute bounds of interpolation area\n",
    "    if bounds is not None:\n",
    "        xmin_bound, xmax_bound = bounds\n",
    "    else:\n",
    "        xmin_bound, xmax_bound = (x1, x2) if x1 <= x2 else (x2, x1)\n",
    "\n",
    "    # Code for most common case: cubic interpolation of 2 points\n",
    "    #   w/ function and derivative values for both\n",
    "    # Solution in this case (where x2 is the farthest point):\n",
    "    #   d1 = g1 + g2 - 3*(f1-f2)/(x1-x2);\n",
    "    #   d2 = sqrt(d1^2 - g1*g2);\n",
    "    #   min_pos = x2 - (x2 - x1)*((g2 + d2 - d1)/(g2 - g1 + 2*d2));\n",
    "    #   t_new = min(max(min_pos,xmin_bound),xmax_bound);\n",
    "    d1 = g1 + g2 - 3 * (f1 - f2) / (x1 - x2)\n",
    "    d2_square = d1**2 - g1 * g2\n",
    "    if d2_square >= 0:\n",
    "        d2 = d2_square.sqrt()\n",
    "        if x1 <= x2:\n",
    "            min_pos = x2 - (x2 - x1) * ((g2 + d2 - d1) / (g2 - g1 + 2 * d2))\n",
    "        else:\n",
    "            min_pos = x1 - (x1 - x2) * ((g1 + d2 - d1) / (g1 - g2 + 2 * d2))\n",
    "        return min(max(min_pos, xmin_bound), xmax_bound)\n",
    "    else:\n",
    "        return (xmin_bound + xmax_bound) / 2.\n",
    "\n",
    "\n",
    "def _strong_wolfe(obj_func,\n",
    "                  x,\n",
    "                  t,\n",
    "                  d,\n",
    "                  f,\n",
    "                  g,\n",
    "                  gtd,\n",
    "                  c1=1e-4,\n",
    "                  c2=0.9,\n",
    "                  tolerance_change=1e-9,\n",
    "                  max_ls=25):\n",
    "    # ported from https://github.com/torch/optim/blob/master/lswolfe.lua\n",
    "    d_norm = d.abs().max()\n",
    "    g = g.clone(memory_format=torch.contiguous_format)\n",
    "    # evaluate objective and gradient using initial step\n",
    "    f_new, g_new = obj_func(x, t, d)\n",
    "    ls_func_evals = 1\n",
    "    gtd_new = g_new.dot(d)\n",
    "\n",
    "    # bracket an interval containing a point satisfying the Wolfe criteria\n",
    "    t_prev, f_prev, g_prev, gtd_prev = 0, f, g, gtd\n",
    "    done = False\n",
    "    ls_iter = 0\n",
    "    while ls_iter < max_ls:\n",
    "        # check conditions\n",
    "        if f_new > (f + c1 * t * gtd) or (ls_iter > 1 and f_new >= f_prev):\n",
    "            bracket = [t_prev, t]\n",
    "            bracket_f = [f_prev, f_new]\n",
    "            bracket_g = [g_prev, g_new.clone(memory_format=torch.contiguous_format)]\n",
    "            bracket_gtd = [gtd_prev, gtd_new]\n",
    "            break\n",
    "\n",
    "        if abs(gtd_new) <= -c2 * gtd:\n",
    "            bracket = [t]\n",
    "            bracket_f = [f_new]\n",
    "            bracket_g = [g_new]\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "        if gtd_new >= 0:\n",
    "            bracket = [t_prev, t]\n",
    "            bracket_f = [f_prev, f_new]\n",
    "            bracket_g = [g_prev, g_new.clone(memory_format=torch.contiguous_format)]\n",
    "            bracket_gtd = [gtd_prev, gtd_new]\n",
    "            break\n",
    "\n",
    "        # interpolate\n",
    "        min_step = t + 0.01 * (t - t_prev)\n",
    "        max_step = t * 10\n",
    "        tmp = t\n",
    "        t = _cubic_interpolate(\n",
    "            t_prev,\n",
    "            f_prev,\n",
    "            gtd_prev,\n",
    "            t,\n",
    "            f_new,\n",
    "            gtd_new,\n",
    "            bounds=(min_step, max_step))\n",
    "\n",
    "        # next step\n",
    "        t_prev = tmp\n",
    "        f_prev = f_new\n",
    "        g_prev = g_new.clone(memory_format=torch.contiguous_format)\n",
    "        gtd_prev = gtd_new\n",
    "        f_new, g_new = obj_func(x, t, d)\n",
    "        ls_func_evals += 1\n",
    "        gtd_new = g_new.dot(d)\n",
    "        ls_iter += 1\n",
    "\n",
    "    # reached max number of iterations?\n",
    "    if ls_iter == max_ls:\n",
    "        bracket = [0, t]\n",
    "        bracket_f = [f, f_new]\n",
    "        bracket_g = [g, g_new]\n",
    "\n",
    "    # zoom phase: we now have a point satisfying the criteria, or\n",
    "    # a bracket around it. We refine the bracket until we find the\n",
    "    # exact point satisfying the criteria\n",
    "    insuf_progress = False\n",
    "    # find high and low points in bracket\n",
    "    low_pos, high_pos = (0, 1) if bracket_f[0] <= bracket_f[-1] else (1, 0)\n",
    "    while not done and ls_iter < max_ls:\n",
    "        # line-search bracket is so small\n",
    "        if abs(bracket[1] - bracket[0]) * d_norm < tolerance_change:\n",
    "            break\n",
    "\n",
    "        # compute new trial value\n",
    "        t = _cubic_interpolate(bracket[0], bracket_f[0], bracket_gtd[0],\n",
    "                               bracket[1], bracket_f[1], bracket_gtd[1])\n",
    "\n",
    "        # test that we are making sufficient progress:\n",
    "        # in case `t` is so close to boundary, we mark that we are making\n",
    "        # insufficient progress, and if\n",
    "        #   + we have made insufficient progress in the last step, or\n",
    "        #   + `t` is at one of the boundary,\n",
    "        # we will move `t` to a position which is `0.1 * len(bracket)`\n",
    "        # away from the nearest boundary point.\n",
    "        eps = 0.1 * (max(bracket) - min(bracket))\n",
    "        if min(max(bracket) - t, t - min(bracket)) < eps:\n",
    "            # interpolation close to boundary\n",
    "            if insuf_progress or t >= max(bracket) or t <= min(bracket):\n",
    "                # evaluate at 0.1 away from boundary\n",
    "                if abs(t - max(bracket)) < abs(t - min(bracket)):\n",
    "                    t = max(bracket) - eps\n",
    "                else:\n",
    "                    t = min(bracket) + eps\n",
    "                insuf_progress = False\n",
    "            else:\n",
    "                insuf_progress = True\n",
    "        else:\n",
    "            insuf_progress = False\n",
    "\n",
    "        # Evaluate new point\n",
    "        f_new, g_new = obj_func(x, t, d)\n",
    "        ls_func_evals += 1\n",
    "        gtd_new = g_new.dot(d)\n",
    "        ls_iter += 1\n",
    "\n",
    "        if f_new > (f + c1 * t * gtd) or f_new >= bracket_f[low_pos]:\n",
    "            # Armijo condition not satisfied or not lower than lowest point\n",
    "            bracket[high_pos] = t\n",
    "            bracket_f[high_pos] = f_new\n",
    "            bracket_g[high_pos] = g_new.clone(memory_format=torch.contiguous_format)\n",
    "            bracket_gtd[high_pos] = gtd_new\n",
    "            low_pos, high_pos = (0, 1) if bracket_f[0] <= bracket_f[1] else (1, 0)\n",
    "        else:\n",
    "            if abs(gtd_new) <= -c2 * gtd:\n",
    "                # Wolfe conditions satisfied\n",
    "                done = True\n",
    "            elif gtd_new * (bracket[high_pos] - bracket[low_pos]) >= 0:\n",
    "                # old low becomes new high\n",
    "                bracket[high_pos] = bracket[low_pos]\n",
    "                bracket_f[high_pos] = bracket_f[low_pos]\n",
    "                bracket_g[high_pos] = bracket_g[low_pos]\n",
    "                bracket_gtd[high_pos] = bracket_gtd[low_pos]\n",
    "\n",
    "            # new point becomes new low\n",
    "            bracket[low_pos] = t\n",
    "            bracket_f[low_pos] = f_new\n",
    "            bracket_g[low_pos] = g_new.clone(memory_format=torch.contiguous_format)\n",
    "            bracket_gtd[low_pos] = gtd_new\n",
    "\n",
    "    # return stuff\n",
    "    t = bracket[low_pos]\n",
    "    f_new = bracket_f[low_pos]\n",
    "    g_new = bracket_g[low_pos]\n",
    "    return f_new, g_new, t, ls_func_evals\n",
    "\n",
    "\n",
    "\n",
    "class LBFGS(Optimizer):\n",
    "    \"\"\"Implements L-BFGS algorithm.\n",
    "\n",
    "    Heavily inspired by `minFunc\n",
    "    <https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html>`_.\n",
    "\n",
    "    .. warning::\n",
    "        This optimizer doesn't support per-parameter options and parameter\n",
    "        groups (there can be only one).\n",
    "\n",
    "    .. warning::\n",
    "        Right now all parameters have to be on a single device. This will be\n",
    "        improved in the future.\n",
    "\n",
    "    .. note::\n",
    "        This is a very memory intensive optimizer (it requires additional\n",
    "        ``param_bytes * (history_size + 1)`` bytes). If it doesn't fit in memory\n",
    "        try reducing the history size, or use a different algorithm.\n",
    "\n",
    "    Args:\n",
    "        lr (float): learning rate (default: 1)\n",
    "        max_iter (int): maximal number of iterations per optimization step\n",
    "            (default: 20)\n",
    "        max_eval (int): maximal number of function evaluations per optimization\n",
    "            step (default: max_iter * 1.25).\n",
    "        tolerance_grad (float): termination tolerance on first order optimality\n",
    "            (default: 1e-7).\n",
    "        tolerance_change (float): termination tolerance on function\n",
    "            value/parameter changes (default: 1e-9).\n",
    "        history_size (int): update history size (default: 100).\n",
    "        line_search_fn (str): either 'strong_wolfe' or None (default: None).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 lr=1,\n",
    "                 max_iter=20,\n",
    "                 max_eval=None,\n",
    "                 tolerance_grad=1e-7,\n",
    "                 tolerance_change=1e-9,\n",
    "                 tolerance_ys=1e-32,\n",
    "                 history_size=100,\n",
    "                 line_search_fn=None):\n",
    "        if max_eval is None:\n",
    "            max_eval = max_iter * 5 // 4\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            max_iter=max_iter,\n",
    "            max_eval=max_eval,\n",
    "            tolerance_grad=tolerance_grad,\n",
    "            tolerance_change=tolerance_change,\n",
    "            tolerance_ys=tolerance_ys,\n",
    "            history_size=history_size,\n",
    "            line_search_fn=line_search_fn)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "        if len(self.param_groups) != 1:\n",
    "            raise ValueError(\"LBFGS doesn't support per-parameter options \"\n",
    "                             \"(parameter groups)\")\n",
    "\n",
    "        self._params = self.param_groups[0]['params']\n",
    "        self._numel_cache = None\n",
    "\n",
    "    def _numel(self):\n",
    "        if self._numel_cache is None:\n",
    "            self._numel_cache = reduce(lambda total, p: total + p.numel(), self._params, 0)\n",
    "        return self._numel_cache\n",
    "\n",
    "    def _gather_flat_grad(self):\n",
    "        views = []\n",
    "        for p in self._params:\n",
    "            if p.grad is None:\n",
    "                view = p.new(p.numel()).zero_()\n",
    "            elif p.grad.is_sparse:\n",
    "                view = p.grad.to_dense().view(-1)\n",
    "            else:\n",
    "                view = p.grad.view(-1)\n",
    "            views.append(view)\n",
    "        return torch.cat(views, 0)\n",
    "\n",
    "    def _add_grad(self, step_size, update):\n",
    "        offset = 0\n",
    "        for p in self._params:\n",
    "            numel = p.numel()\n",
    "            # view as to avoid deprecated pointwise semantics\n",
    "            p.add_(update[offset:offset + numel].view_as(p), alpha=step_size)\n",
    "            offset += numel\n",
    "        assert offset == self._numel()\n",
    "\n",
    "    def _clone_param(self):\n",
    "        return [p.clone(memory_format=torch.contiguous_format) for p in self._params]\n",
    "\n",
    "    def _set_param(self, params_data):\n",
    "        for p, pdata in zip(self._params, params_data):\n",
    "            p.copy_(pdata)\n",
    "\n",
    "    def _directional_evaluate(self, closure, x, t, d):\n",
    "        self._add_grad(t, d)\n",
    "        loss = float(closure())\n",
    "        flat_grad = self._gather_flat_grad()\n",
    "        self._set_param(x)\n",
    "        return loss, flat_grad\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure):\n",
    "        \"\"\"Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            closure (Callable): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        assert len(self.param_groups) == 1\n",
    "\n",
    "        # Make sure the closure is always called with grad enabled\n",
    "        closure = torch.enable_grad()(closure)\n",
    "\n",
    "        group = self.param_groups[0]\n",
    "        lr = group['lr']\n",
    "        max_iter = group['max_iter']\n",
    "        max_eval = group['max_eval']\n",
    "        tolerance_grad = group['tolerance_grad']\n",
    "        tolerance_change = group['tolerance_change']\n",
    "        tolerance_ys = group['tolerance_ys']\n",
    "        line_search_fn = group['line_search_fn']\n",
    "        history_size = group['history_size']\n",
    "\n",
    "        # NOTE: LBFGS has only global state, but we register it as state for\n",
    "        # the first param, because this helps with casting in load_state_dict\n",
    "        state = self.state[self._params[0]]\n",
    "        state.setdefault('func_evals', 0)\n",
    "        state.setdefault('n_iter', 0)\n",
    "\n",
    "        # evaluate initial f(x) and df/dx\n",
    "        orig_loss = closure()\n",
    "        loss = float(orig_loss)\n",
    "        current_evals = 1\n",
    "        state['func_evals'] += 1\n",
    "\n",
    "        flat_grad = self._gather_flat_grad()\n",
    "        opt_cond = flat_grad.abs().max() <= tolerance_grad\n",
    "\n",
    "        # optimal condition\n",
    "        if opt_cond:\n",
    "            return orig_loss\n",
    "\n",
    "        # tensors cached in state (for tracing)\n",
    "        d = state.get('d')\n",
    "        t = state.get('t')\n",
    "        old_dirs = state.get('old_dirs')\n",
    "        old_stps = state.get('old_stps')\n",
    "        ro = state.get('ro')\n",
    "        H_diag = state.get('H_diag')\n",
    "        prev_flat_grad = state.get('prev_flat_grad')\n",
    "        prev_loss = state.get('prev_loss')\n",
    "\n",
    "        n_iter = 0\n",
    "        # optimize for a max of max_iter iterations\n",
    "        while n_iter < max_iter:\n",
    "            # keep track of nb of iterations\n",
    "            n_iter += 1\n",
    "            state['n_iter'] += 1\n",
    "\n",
    "            ############################################################\n",
    "            # compute gradient descent direction\n",
    "            ############################################################\n",
    "            if state['n_iter'] == 1:\n",
    "                d = flat_grad.neg()\n",
    "                old_dirs = []\n",
    "                old_stps = []\n",
    "                ro = []\n",
    "                H_diag = 1\n",
    "            else:\n",
    "                # do lbfgs update (update memory)\n",
    "                y = flat_grad.sub(prev_flat_grad)\n",
    "                s = d.mul(t)\n",
    "                ys = y.dot(s)  # y*s\n",
    "                if ys > tolerance_ys:\n",
    "                    # updating memory\n",
    "                    if len(old_dirs) == history_size:\n",
    "                        # shift history by one (limited-memory)\n",
    "                        old_dirs.pop(0)\n",
    "                        old_stps.pop(0)\n",
    "                        ro.pop(0)\n",
    "\n",
    "                    # store new direction/step\n",
    "                    old_dirs.append(y)\n",
    "                    old_stps.append(s)\n",
    "                    ro.append(1. / ys)\n",
    "\n",
    "                    # update scale of initial Hessian approximation\n",
    "                    H_diag = ys / y.dot(y)  # (y*y)\n",
    "\n",
    "                # compute the approximate (L-BFGS) inverse Hessian\n",
    "                # multiplied by the gradient\n",
    "                num_old = len(old_dirs)\n",
    "\n",
    "                if 'al' not in state:\n",
    "                    state['al'] = [None] * history_size\n",
    "                al = state['al']\n",
    "\n",
    "                # iteration in L-BFGS loop collapsed to use just one buffer\n",
    "                q = flat_grad.neg()\n",
    "                for i in range(num_old - 1, -1, -1):\n",
    "                    al[i] = old_stps[i].dot(q) * ro[i]\n",
    "                    q.add_(old_dirs[i], alpha=-al[i])\n",
    "\n",
    "                # multiply by initial Hessian\n",
    "                # r/d is the final direction\n",
    "                d = r = torch.mul(q, H_diag)\n",
    "                for i in range(num_old):\n",
    "                    be_i = old_dirs[i].dot(r) * ro[i]\n",
    "                    r.add_(old_stps[i], alpha=al[i] - be_i)\n",
    "\n",
    "            if prev_flat_grad is None:\n",
    "                prev_flat_grad = flat_grad.clone(memory_format=torch.contiguous_format)\n",
    "            else:\n",
    "                prev_flat_grad.copy_(flat_grad)\n",
    "            prev_loss = loss\n",
    "\n",
    "            ############################################################\n",
    "            # compute step length\n",
    "            ############################################################\n",
    "            # reset initial guess for step size\n",
    "            if state['n_iter'] == 1:\n",
    "                t = min(1., 1. / flat_grad.abs().sum()) * lr\n",
    "            else:\n",
    "                t = lr\n",
    "\n",
    "            # directional derivative\n",
    "            gtd = flat_grad.dot(d)  # g * d\n",
    "\n",
    "            # directional derivative is below tolerance\n",
    "            if gtd > -tolerance_change:\n",
    "                break\n",
    "\n",
    "            # optional line search: user function\n",
    "            ls_func_evals = 0\n",
    "            if line_search_fn is not None:\n",
    "                # perform line search, using user function\n",
    "                if line_search_fn != \"strong_wolfe\":\n",
    "                    raise RuntimeError(\"only 'strong_wolfe' is supported\")\n",
    "                else:\n",
    "                    x_init = self._clone_param()\n",
    "\n",
    "                    def obj_func(x, t, d):\n",
    "                        return self._directional_evaluate(closure, x, t, d)\n",
    "\n",
    "                    loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n",
    "                        obj_func, x_init, t, d, loss, flat_grad, gtd)\n",
    "                self._add_grad(t, d)\n",
    "                opt_cond = flat_grad.abs().max() <= tolerance_grad\n",
    "            else:\n",
    "                # no line search, simply move with fixed-step\n",
    "                self._add_grad(t, d)\n",
    "                if n_iter != max_iter:\n",
    "                    # re-evaluate function only if not in last iteration\n",
    "                    # the reason we do this: in a stochastic setting,\n",
    "                    # no use to re-evaluate that function here\n",
    "                    with torch.enable_grad():\n",
    "                        loss = float(closure())\n",
    "                    flat_grad = self._gather_flat_grad()\n",
    "                    opt_cond = flat_grad.abs().max() <= tolerance_grad\n",
    "                    ls_func_evals = 1\n",
    "\n",
    "            # update func eval\n",
    "            current_evals += ls_func_evals\n",
    "            state['func_evals'] += ls_func_evals\n",
    "\n",
    "            ############################################################\n",
    "            # check conditions\n",
    "            ############################################################\n",
    "            if n_iter == max_iter:\n",
    "                break\n",
    "\n",
    "            if current_evals >= max_eval:\n",
    "                break\n",
    "\n",
    "            # optimal condition\n",
    "            if opt_cond:\n",
    "                break\n",
    "\n",
    "            # lack of progress\n",
    "            if d.mul(t).abs().max() <= tolerance_change:\n",
    "                break\n",
    "\n",
    "            if abs(loss - prev_loss) < tolerance_change:\n",
    "                break\n",
    "\n",
    "        state['d'] = d\n",
    "        state['t'] = t\n",
    "        state['old_dirs'] = old_dirs\n",
    "        state['old_stps'] = old_stps\n",
    "        state['ro'] = ro\n",
    "        state['H_diag'] = H_diag\n",
    "        state['prev_flat_grad'] = prev_flat_grad\n",
    "        state['prev_loss'] = prev_loss\n",
    "\n",
    "        return orig_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.639538200Z",
     "start_time": "2024-05-20T09:17:36.384502200Z"
    }
   },
   "id": "8ac7289b75ff51f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KAN.py\n",
    "包含了定义了KAN模型的主要类或函数，负责模型的建立和训练流程。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb6429fa54212413"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "\n",
    "'''\n",
    "属性，参数和超参数：\n",
    "    ·biases 是一个包含 nn.Linear() 的列表。表示在节点上添加的偏置（原则上，偏置可以被吸收到激活函数中，但实际中我们仍然会保留它们以进行更好的优化）；  \n",
    "    ·act_fun 是一个包含 KANLayer 的列表，表示 KAN 层，即带有可学习参数的激活函数； \n",
    "    ·depth 是一个整数，表示 KAN 的深度，即神经网络中的层数； \n",
    "    ·width 是一个列表，表示每层中神经元的数量。例如，[2,5,5,3] 表示 2D 输入，5D 输出，具有 2 层 5 个隐藏神经元；\n",
    "    ·grid 是一个整数，表示网格间隔的数量； \n",
    "    ·k 是一个整数，表示分段多项式的阶数；\n",
    "    ·base_fun 是一个函数，表示残差函数 b(x) 的激活函数 phi(x) = sb_scale * b(x) + sp_scale * spline(x)；\n",
    "    ·symbolic_fun 是一个包含 Symbolic_KANLayer 的列表，表示符号 KAN 层；\n",
    "    ·symbolic_enabled 是一个布尔值，如果为 False，则不计算符号前端（以节省时间），默认为 True。\n",
    "方法和函数：\n",
    "    ·init(): 初始化一个 KAN（KANLayer Activation Network）。\n",
    "    ·initialize_from_another_model(): 从另一个 KAN（具有相同形状但可能具有不同网格）初始化一个 KAN。\n",
    "    ·update_grid_from_samples(): 根据样本更新样条网格。\n",
    "    ·initialize_grid_from_another_model(): 从另一个 KAN 初始化 KAN 的网格。\n",
    "    ·forward(): 前向传播计算输出。\n",
    "    ·set_mode(): 设置激活函数的模式，'n' 表示数值模式，'s' 表示符号模式，'ns' 表示组合模式（在 ·plot() 中以不同颜色展示：数值为黑色，符号为红色，组合为紫色）。\n",
    "    ·fix_symbolic(): 将激活函数固定为符号函数。\n",
    "    ·suggest_symbolic(): 提示将数值样条激活函数转换为符号函数的候选方法。\n",
    "    ·lock(): 锁定激活函数以共享参数。\n",
    "    ·unlock(): 解锁已锁定的激活函数。\n",
    "    ·get_range(): 获取激活函数的输入和输出范围。\n",
    "    ·plot(): 绘制 KAN 的图示。\n",
    "    ·train(): 训练 KAN。\n",
    "    ·prune(): 对 KAN 进行剪枝。\n",
    "    ·remove_edge(): 移除 KAN 的某些边。\n",
    "    ·remove_node(): 移除 KAN 的某些节点。\n",
    "    ·auto_symbolic(): 自动将所有样条拟合为符号函数。\n",
    "    ·symbolic_formula(): 获取 KAN 网络的符号公式。\n",
    "'''\n",
    "\n",
    "class KAN(nn.Module):\n",
    "    def __init__(self, width=None, grid=3, k=3, noise_scale=0.1, noise_scale_base=0.1, base_fun=nn.SiLU(),\n",
    "                 symbolic_enabled=True, bias_trainable=True, grid_eps=1.0, grid_range=[-1, 1], sp_trainable=True,\n",
    "                 sb_trainable=True, device='cpu', seed=0,):\n",
    "        \"\"\"\n",
    "        :param width: list of int，指定每个层的神经元数量（包括输入和输出）。\n",
    "        :param grid: int，网格间隔的数量。默认值为3。\n",
    "        :param k: int，分段多项式的阶数。默认值为3。\n",
    "        :param noise_scale: float，初始注入到样条中的噪声大小。默认值为0.1。\n",
    "        :param noise_scale_base: float，初始注入到基础函数中的噪声大小。默认值为0.1。\n",
    "        :param base_fun: fun，残差函数b(x)的基础函数。默认值为torch.nn.SiLU()（Sigmoid Linear Unit）。\n",
    "        :param symbolic_enabled: bool，是否进行符号计算（用于提高效率）。默认值为True。\n",
    "        :param bias_trainable: bool，是否更新偏置参数。默认值为True。\n",
    "        :param grid_eps: float，当 grid_eps = 0 时，网格是均匀的；当 grid_eps = 1 时，网格使用样本的百分位数进行划分。0 < grid_eps < 1 插值了这两个极端情况。默认值为 0.02。\n",
    "        :param grid_range: list/np.array of shape (2,))，网格的范围。默认值为[-1, 1]。\n",
    "        :param sp_trainable: bool，如果为True，则scale_sp可训练。默认值为True\n",
    "        :param sb_trainable: bool，如果为True，则scale_base可训练。默认值为True\n",
    "        :param device: str，设备名称，用于指定计算设备（如\"cpu\"或\"gpu\")\n",
    "        :param seed: int，随机种子，用于初始化随机数生成器\n",
    "        \"\"\"\n",
    "        super(KAN, self).__init__()\n",
    "        \n",
    "        # 设置PyTorch框架，numpy包，python内置随机数生成器的种子\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # 初始化神经网络的权重和偏置参数\n",
    "        self.biases = []\n",
    "        self.act_fun = []\n",
    "        self.depth = len(width) - 1\n",
    "        self.width = width\n",
    "        \n",
    "        # 初始化KAN模型的样条插值层和偏置参数层\n",
    "        '''\n",
    "        ①首先，循环遍历每一层神经网络。在每层中，通过设置缩放参数scale_base初始化样条插值层sp_batch。具体地，根据输入层和输出层的大小，随机生成一个尺寸为(width[l] * width[l + 1],)的张量，并乘上一个缩放因子1 / np.sqrt(width[l])。然后，将其作为参数传入KANLayer的构造函数中，生成样条插值层sp_batch。\n",
    "        ②接着，通过nn.Linear函数初始化偏置参数层bias，并将其加入到self.biases中。在这里，nn.Linear函数的输入大小为width[l+1]，输出大小为1，且不含偏置项。同时，将偏置参数的梯度设置为bias_trainable参数所指定的值，并将权重初始化为0。\n",
    "        ③最后，将初始化好的样条插值层和偏置参数层存储在self.act_fun和self.biases中。\n",
    "        '''\n",
    "        for l in range(self.depth):\n",
    "            # splines\n",
    "            scale_base = 1 / np.sqrt(width[l]) + (torch.randn(width[l] * width[l + 1], ) * 2 - 1) * noise_scale_base\n",
    "            sp_batch = KANLayer(in_dim=width[l], out_dim=width[l + 1], num=grid, k=k, noise_scale=noise_scale, scale_base=scale_base, scale_sp=1., base_fun=base_fun, grid_eps=grid_eps, grid_range=grid_range, sp_trainable=sp_trainable,\n",
    "                                sb_trainable=sb_trainable, device=device)\n",
    "            self.act_fun.append(sp_batch)\n",
    "\n",
    "            # bias\n",
    "            bias = nn.Linear(width[l + 1], 1, bias=False, device=device).requires_grad_(bias_trainable)\n",
    "            bias.weight.data *= 0.\n",
    "            self.biases.append(bias)\n",
    "            \n",
    "        # 将偏置参数层和样条插值层转换为PyTorch的模块列表\n",
    "        self.biases = nn.ModuleList(self.biases)\n",
    "        self.act_fun = nn.ModuleList(self.act_fun)\n",
    "\n",
    "        self.grid = grid\n",
    "        self.k = k\n",
    "        self.base_fun = base_fun\n",
    "        \n",
    "        # 初始化符号KAN层\n",
    "        self.symbolic_fun = []\n",
    "        for l in range(self.depth):\n",
    "            sb_batch = Symbolic_KANLayer(in_dim=width[l], out_dim=width[l + 1], device=device)\n",
    "            self.symbolic_fun.append(sb_batch)\n",
    "\n",
    "        self.symbolic_fun = nn.ModuleList(self.symbolic_fun)\n",
    "        self.symbolic_enabled = symbolic_enabled\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "    def initialize_from_another_model(self, another_model, x):\n",
    "        '''\n",
    "        函数initialize_from_another_model接受两个参数：another_model表示另一个KAN模型，x表示输入数据。该函数的主要作用是将another_model中的参数和激活函数的系数传递给当前模型，以实现参数的初始化。\n",
    "        '''\n",
    "        \"\"\"\n",
    "        从一个父模型初始化。该父模型具有与当前模型相同的宽度，但可能具有不同的网格。\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            another_model : KAN\n",
    "                用作初始化当前模型的父模型\n",
    "            x : 2D torch.float\n",
    "                输入，形状为 (batch, 输入维度)\n",
    "        \n",
    "        返回值:\n",
    "        --------\n",
    "            self : KAN\n",
    "        \"\"\"\n",
    "        \n",
    "        another_model(x.to(another_model.device))  # get activations\n",
    "        batch = x.shape[0]\n",
    "        \n",
    "        self.initialize_grid_from_another_model(another_model, x.to(another_model.device))\n",
    "        \n",
    "        for l in range(self.depth):\n",
    "            spb = self.act_fun[l]\n",
    "            spb_parent = another_model.act_fun[l]\n",
    "\n",
    "            # spb = spb_parent\n",
    "            preacts = another_model.spline_preacts[l]\n",
    "            postsplines = another_model.spline_postsplines[l]\n",
    "            self.act_fun[l].coef.data = curve2coef(preacts.reshape(batch, spb.size).permute(1, 0), postsplines.reshape(batch, spb.size).permute(1, 0), spb.grid, k=spb.k, device=self.device)\n",
    "            spb.scale_base.data = spb_parent.scale_base.data\n",
    "            spb.scale_sp.data = spb_parent.scale_sp.data\n",
    "            spb.mask.data = spb_parent.mask.data\n",
    "            # print(spb.mask.data, self.act_fun[l].mask.data)\n",
    "\n",
    "        for l in range(self.depth):\n",
    "            self.biases[l].weight.data = another_model.biases[l].weight.data\n",
    "\n",
    "        for l in range(self.depth):\n",
    "            self.symbolic_fun[l] = another_model.symbolic_fun[l]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def update_grid_from_samples(self, x):\n",
    "        '''\n",
    "        参数:\n",
    "        -----\n",
    "            x : 2D torch.float\n",
    "                输入，形状为（批次，输入维度）\n",
    "\n",
    "        '''\n",
    "        for l in range(self.depth):\n",
    "            self.forward(x)\n",
    "            self.act_fun[l].update_grid_from_samples(self.acts[l])\n",
    "            \n",
    "    def initialize_grid_from_another_model(self, model, x):\n",
    "        '''\n",
    "        从另一个模型初始化网格\n",
    "        \n",
    "        参数:\n",
    "        -----\n",
    "            another_model : KAN\n",
    "                用作初始化当前模型的父模型\n",
    "            x : 2D torch.float\n",
    "                输入，形状为 (batch, 输入维度)\n",
    "\n",
    "        '''\n",
    "        model(x)\n",
    "        for l in range(self.depth):\n",
    "            self.act_fun[l].initialize_grid_from_parent(model.act_fun[l], model.acts[l])\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        KAN前向传播\n",
    "        \n",
    "        参数:\n",
    "        x : 2D torch.float\n",
    "            输入，形状为 (批次大小, 输入维度)\n",
    "        返回值:\n",
    "        y : 2D torch.float\n",
    "            输出，形状为 (批次大小, 输出维度)\n",
    "        '''\n",
    "\n",
    "        self.acts = []  # shape ([batch, n0], [batch, n1], ..., [batch, n_L])\n",
    "        self.spline_preacts = []\n",
    "        self.spline_postsplines = []\n",
    "        self.spline_postacts = []\n",
    "        self.acts_scale = []\n",
    "        self.acts_scale_std = []\n",
    "        # self.neurons_scale = []\n",
    "\n",
    "        self.acts.append(x)  # acts shape: (batch, width[l])\n",
    "\n",
    "        for l in range(self.depth):\n",
    "\n",
    "            x_numerical, preacts, postacts_numerical, postspline = self.act_fun[l](x)\n",
    "\n",
    "            if self.symbolic_enabled == True:\n",
    "                x_symbolic, postacts_symbolic = self.symbolic_fun[l](x)\n",
    "            else:\n",
    "                x_symbolic = 0.\n",
    "                postacts_symbolic = 0.\n",
    "\n",
    "            x = x_numerical + x_symbolic\n",
    "            postacts = postacts_numerical + postacts_symbolic\n",
    "\n",
    "            # self.neurons_scale.append(torch.mean(torch.abs(x), dim=0))\n",
    "            grid_reshape = self.act_fun[l].grid.reshape(self.width[l + 1], self.width[l], -1)\n",
    "            input_range = grid_reshape[:, :, -1] - grid_reshape[:, :, 0] + 1e-4\n",
    "            output_range = torch.mean(torch.abs(postacts), dim=0)\n",
    "            self.acts_scale.append(output_range / input_range)\n",
    "            self.acts_scale_std.append(torch.std(postacts, dim=0))\n",
    "            self.spline_preacts.append(preacts.detach())\n",
    "            self.spline_postacts.append(postacts.detach())\n",
    "            self.spline_postsplines.append(postspline.detach())\n",
    "\n",
    "            x = x + self.biases[l].weight\n",
    "            self.acts.append(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def set_mode(self, l, i, j, mode, mask_n=None):\n",
    "        '''\n",
    "        设置 (l, i, j) 激活以采用指定模式\n",
    "        \n",
    "        参数:\n",
    "        l : int\n",
    "            层索引\n",
    "        i : int\n",
    "            输入神经元索引\n",
    "        j : int\n",
    "            输出神经元索引\n",
    "        mode : str\n",
    "            'n'（数值）或 's'（符号）或 'ns'（混合）\n",
    "        mask_n : None 或 float\n",
    "            数值部分的幅度\n",
    "\n",
    "        '''\n",
    "        if mode == \"s\":\n",
    "            mask_n = 0.;\n",
    "            mask_s = 1.\n",
    "        elif mode == \"n\":\n",
    "            mask_n = 1.;\n",
    "            mask_s = 0.\n",
    "        elif mode == \"sn\" or mode == \"ns\":\n",
    "            if mask_n == None:\n",
    "                mask_n = 1.\n",
    "            else:\n",
    "                mask_n = mask_n\n",
    "            mask_s = 1.\n",
    "        else:\n",
    "            mask_n = 0.;\n",
    "            mask_s = 0.\n",
    "\n",
    "        self.act_fun[l].mask.data[j * self.act_fun[l].in_dim + i] = mask_n\n",
    "        self.symbolic_fun[l].mask.data[j, i] = mask_s\n",
    "        \n",
    "    def fix_symbolic(self, l, i, j, fun_name, fit_params_bool=True, a_range=(-10, 10), b_range=(-10, 10), verbose=True, random=False):\n",
    "        '''\n",
    "        将 (l, i, j) 激活设置为符号形式（由fun_name指定）\n",
    "        \n",
    "        参数:\n",
    "        l : int\n",
    "            层索引\n",
    "        i : int\n",
    "            输入神经元索引\n",
    "        j : int\n",
    "            输出神经元索引\n",
    "        fun_name : str\n",
    "            函数名称\n",
    "        fit_params_bool : bool\n",
    "            是否通过拟合获取仿射参数（True）或设置默认值（False）\n",
    "        a_range : tuple\n",
    "            a的取值范围\n",
    "        b_range : tuple\n",
    "            b的取值范围\n",
    "        verbose : bool\n",
    "            如果为True，会打印更多信息。\n",
    "        random : bool\n",
    "            随机初始化仿射参数还是使用默认值[1,0,1,0]\n",
    "        返回值:\n",
    "        None 或 r2 (决定系数)\n",
    "        '''\n",
    "        self.set_mode(l, i, j, mode=\"s\")\n",
    "        if not fit_params_bool:\n",
    "            self.symbolic_fun[l].fix_symbolic(i, j, fun_name, verbose=verbose, random=random)\n",
    "            return None\n",
    "        else:\n",
    "            x = self.acts[l][:, i]\n",
    "            y = self.spline_postacts[l][:, j, i]\n",
    "            r2 = self.symbolic_fun[l].fix_symbolic(i, j, fun_name, x, y, a_range=a_range, b_range=b_range, verbose=verbose)\n",
    "            return r2\n",
    "        \n",
    "    def unfix_symbolic(self, l, i, j):\n",
    "        '''\n",
    "        取消固定 (l, i, j) 激活函数。\n",
    "        '''\n",
    "        self.set_mode(l, i, j, mode=\"n\")\n",
    "\n",
    "    def unfix_symbolic_all(self):\n",
    "        '''\n",
    "        取消固定所有激活函数。\n",
    "        '''\n",
    "        for l in range(len(self.width) - 1):\n",
    "            for i in range(self.width[l]):\n",
    "                for j in range(self.width[l + 1]):\n",
    "                    self.unfix_symbolic(l, i, j)\n",
    "                    \n",
    "    def lock(self, l, ids):\n",
    "        '''\n",
    "        将第l层中的神经元的激活函数设置为相同的函数\n",
    "        \n",
    "            参数:\n",
    "            -----\n",
    "                l : int\n",
    "                    层索引\n",
    "                ids : 2D列表\n",
    "                    :math:`[[i_1,j_1],[i_2,j_2],...]` 设置 :math:`(l,i_i,j_1), (l,i_2,j_2), ...` 的激活函数相同\n",
    "\n",
    "            '''\n",
    "        self.act_fun[l].lock(ids)    \n",
    "        \n",
    "    def unlock(self, l, ids):\n",
    "        '''\n",
    "        将第l层中的神经元的激活函数解锁，允许它们使用不同的函数\n",
    "        \n",
    "            参数:\n",
    "            -----\n",
    "                l : int\n",
    "                    层索引\n",
    "                ids : 2D列表\n",
    "                    [[i1,j1],[i2,j2],...] 设置 (l,ii,j1), (l,i2,j2), ... 的激活函数为解锁状态\n",
    "            '''\n",
    "        self.act_fun[l].unlock(ids)\n",
    "\n",
    "    def get_range(self, l, i, j, verbose=True):\n",
    "        '''\n",
    "        获取(l,i,j)激活函数的输入范围和输出范围\n",
    "        \n",
    "            参数:\n",
    "            -----\n",
    "                l : int\n",
    "                    层索引\n",
    "                i : int\n",
    "                    输入神经元索引\n",
    "                j : int\n",
    "                    输出神经元索引\n",
    "            \n",
    "            返回值:\n",
    "            --------\n",
    "                x_min : float\n",
    "                    输入的最小值\n",
    "                x_max : float\n",
    "                    输入的最大值\n",
    "                y_min : float\n",
    "                    输出的最小值\n",
    "                y_max : float\n",
    "                    输出的最大值\n",
    "            '''\n",
    "        x = self.spline_preacts[l][:, j, i]\n",
    "        y = self.spline_postacts[l][:, j, i]\n",
    "        x_min = torch.min(x)\n",
    "        x_max = torch.max(x)\n",
    "        y_min = torch.min(y)\n",
    "        y_max = torch.max(y)\n",
    "        if verbose:\n",
    "            print('x range: [' + '%.2f' % x_min, ',', '%.2f' % x_max, ']')\n",
    "            print('y range: [' + '%.2f' % y_min, ',', '%.2f' % y_max, ']')\n",
    "        return x_min, x_max, y_min, y_max\n",
    "    \n",
    "    def plot(self, folder=\"./figures\", beta=3, mask=False, mode=\"supervised\", scale=0.5, tick=False, sample=False, in_vars=None, out_vars=None, title=None):\n",
    "        '''\n",
    "        plot KAN\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            folder : str\n",
    "                the folder to store pngs\n",
    "            beta : float\n",
    "                positive number. control the transparency of each activation. transparency = tanh(beta*l1).\n",
    "            mask : bool\n",
    "                If True, plot with mask (need to run prune() first to obtain mask). If False (by default), plot all activation functions.\n",
    "            mode : bool\n",
    "                \"supervised\" or \"unsupervised\". If \"supervised\", l1 is measured by absolution value (not subtracting mean); if \"unsupervised\", l1 is measured by standard deviation (subtracting mean).\n",
    "            scale : float\n",
    "                control the size of the diagram\n",
    "            in_vars: None or list of str\n",
    "                the name(s) of input variables\n",
    "            out_vars: None or list of str\n",
    "                the name(s) of output variables\n",
    "            title: None or str\n",
    "                title\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            Figure\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        >>> # see more interactive examples in demos\n",
    "        >>> model = KAN(width=[2,3,1], grid=3, k=3, noise_scale=1.0)\n",
    "        >>> x = torch.normal(0,1,size=(100,2))\n",
    "        >>> model(x) # do a forward pass to obtain model.acts\n",
    "        >>> model.plot()\n",
    "        '''\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        # matplotlib.use('Agg')\n",
    "        depth = len(self.width) - 1\n",
    "        for l in range(depth):\n",
    "            w_large = 2.0\n",
    "            for i in range(self.width[l]):\n",
    "                for j in range(self.width[l + 1]):\n",
    "                    rank = torch.argsort(self.acts[l][:, i])\n",
    "                    fig, ax = plt.subplots(figsize=(w_large, w_large))\n",
    "\n",
    "                    num = rank.shape[0]\n",
    "\n",
    "                    symbol_mask = self.symbolic_fun[l].mask[j][i]\n",
    "                    numerical_mask = self.act_fun[l].mask.reshape(self.width[l + 1], self.width[l])[j][i]\n",
    "                    if symbol_mask > 0. and numerical_mask > 0.:\n",
    "                        color = 'purple'\n",
    "                        alpha_mask = 1\n",
    "                    if symbol_mask > 0. and numerical_mask == 0.:\n",
    "                        color = \"red\"\n",
    "                        alpha_mask = 1\n",
    "                    if symbol_mask == 0. and numerical_mask > 0.:\n",
    "                        color = \"black\"\n",
    "                        alpha_mask = 1\n",
    "                    if symbol_mask == 0. and numerical_mask == 0.:\n",
    "                        color = \"white\"\n",
    "                        alpha_mask = 0\n",
    "\n",
    "                    if tick == True:\n",
    "                        ax.tick_params(axis=\"y\", direction=\"in\", pad=-22, labelsize=50)\n",
    "                        ax.tick_params(axis=\"x\", direction=\"in\", pad=-15, labelsize=50)\n",
    "                        x_min, x_max, y_min, y_max = self.get_range(l, i, j, verbose=False)\n",
    "                        plt.xticks([x_min, x_max], ['%2.f' % x_min, '%2.f' % x_max])\n",
    "                        plt.yticks([y_min, y_max], ['%2.f' % y_min, '%2.f' % y_max])\n",
    "                    else:\n",
    "                        plt.xticks([])\n",
    "                        plt.yticks([])\n",
    "                    if alpha_mask == 1:\n",
    "                        plt.gca().patch.set_edgecolor('black')\n",
    "                    else:\n",
    "                        plt.gca().patch.set_edgecolor('white')\n",
    "                    plt.gca().patch.set_linewidth(1.5)\n",
    "                    # plt.axis('off')\n",
    "\n",
    "                    plt.plot(self.acts[l][:, i][rank].cpu().detach().numpy(), self.spline_postacts[l][:, j, i][rank].cpu().detach().numpy(), color=color, lw=5)\n",
    "                    if sample == True:\n",
    "                        plt.scatter(self.acts[l][:, i][rank].cpu().detach().numpy(), self.spline_postacts[l][:, j, i][rank].cpu().detach().numpy(), color=color, s=400 * scale ** 2)\n",
    "                    plt.gca().spines[:].set_color(color)\n",
    "\n",
    "                    lock_id = self.act_fun[l].lock_id[j * self.width[l] + i].long().item()\n",
    "                    if lock_id > 0:\n",
    "                        im = plt.imread(f'{folder}/lock.png')\n",
    "                        newax = fig.add_axes([0.15, 0.7, 0.15, 0.15])\n",
    "                        plt.text(500, 400, lock_id, fontsize=15)\n",
    "                        newax.imshow(im)\n",
    "                        newax.axis('off')\n",
    "\n",
    "                    plt.savefig(f'{folder}/sp_{l}_{i}_{j}.png', bbox_inches=\"tight\", dpi=400)\n",
    "                    plt.close()\n",
    "\n",
    "        def score2alpha(score):\n",
    "            return np.tanh(beta * score)\n",
    "\n",
    "        if mode == \"supervised\":\n",
    "            alpha = [score2alpha(score.cpu().detach().numpy()) for score in self.acts_scale]\n",
    "        elif mode == \"unsupervised\":\n",
    "            alpha = [score2alpha(score.cpu().detach().numpy()) for score in self.acts_scale_std]\n",
    "\n",
    "        # draw skeleton\n",
    "        width = np.array(self.width)\n",
    "        A = 1\n",
    "        y0 = 0.4  # 0.4\n",
    "\n",
    "        # plt.figure(figsize=(5,5*(neuron_depth-1)*y0))\n",
    "        neuron_depth = len(width)\n",
    "        min_spacing = A / np.maximum(np.max(width), 5)\n",
    "\n",
    "        max_neuron = np.max(width)\n",
    "        max_num_weights = np.max(width[:-1] * width[1:])\n",
    "        y1 = 0.4 / np.maximum(max_num_weights, 3)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10 * scale, 10 * scale * (neuron_depth - 1) * y0))\n",
    "        # fig, ax = plt.subplots(figsize=(5,5*(neuron_depth-1)*y0))\n",
    "\n",
    "        # plot scatters and lines\n",
    "        for l in range(neuron_depth):\n",
    "            n = width[l]\n",
    "            spacing = A / n\n",
    "            for i in range(n):\n",
    "                plt.scatter(1 / (2 * n) + i / n, l * y0, s=min_spacing ** 2 * 10000 * scale ** 2, color='black')\n",
    "\n",
    "                if l < neuron_depth - 1:\n",
    "                    # plot connections\n",
    "                    n_next = width[l + 1]\n",
    "                    N = n * n_next\n",
    "                    for j in range(n_next):\n",
    "                        id_ = i * n_next + j\n",
    "\n",
    "                        symbol_mask = self.symbolic_fun[l].mask[j][i]\n",
    "                        numerical_mask = self.act_fun[l].mask.reshape(self.width[l + 1], self.width[l])[j][i]\n",
    "                        if symbol_mask == 1. and numerical_mask == 1.:\n",
    "                            color = 'purple'\n",
    "                            alpha_mask = 1.\n",
    "                        if symbol_mask == 1. and numerical_mask == 0.:\n",
    "                            color = \"red\"\n",
    "                            alpha_mask = 1.\n",
    "                        if symbol_mask == 0. and numerical_mask == 1.:\n",
    "                            color = \"black\"\n",
    "                            alpha_mask = 1.\n",
    "                        if symbol_mask == 0. and numerical_mask == 0.:\n",
    "                            color = \"white\"\n",
    "                            alpha_mask = 0.\n",
    "                        if mask == True:\n",
    "                            plt.plot([1 / (2 * n) + i / n, 1 / (2 * N) + id_ / N], [l * y0, (l + 1 / 2) * y0 - y1], color=color, lw=2 * scale, alpha=alpha[l][j][i] * self.mask[l][i].item() * self.mask[l + 1][j].item())\n",
    "                            plt.plot([1 / (2 * N) + id_ / N, 1 / (2 * n_next) + j / n_next], [(l + 1 / 2) * y0 + y1, (l + 1) * y0], color=color, lw=2 * scale, alpha=alpha[l][j][i] * self.mask[l][i].item() * self.mask[l + 1][j].item())\n",
    "                        else:\n",
    "                            plt.plot([1 / (2 * n) + i / n, 1 / (2 * N) + id_ / N], [l * y0, (l + 1 / 2) * y0 - y1], color=color, lw=2 * scale, alpha=alpha[l][j][i] * alpha_mask)\n",
    "                            plt.plot([1 / (2 * N) + id_ / N, 1 / (2 * n_next) + j / n_next], [(l + 1 / 2) * y0 + y1, (l + 1) * y0], color=color, lw=2 * scale, alpha=alpha[l][j][i] * alpha_mask)\n",
    "\n",
    "            plt.xlim(0, 1)\n",
    "            plt.ylim(-0.1 * y0, (neuron_depth - 1 + 0.1) * y0)\n",
    "\n",
    "        # -- Transformation functions\n",
    "        DC_to_FC = ax.transData.transform\n",
    "        FC_to_NFC = fig.transFigure.inverted().transform\n",
    "        # -- Take data coordinates and transform them to normalized figure coordinates\n",
    "        DC_to_NFC = lambda x: FC_to_NFC(DC_to_FC(x))\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        # plot splines\n",
    "        for l in range(neuron_depth - 1):\n",
    "            n = width[l]\n",
    "            for i in range(n):\n",
    "                n_next = width[l + 1]\n",
    "                N = n * n_next\n",
    "                for j in range(n_next):\n",
    "                    id_ = i * n_next + j\n",
    "                    im = plt.imread(f'{folder}/sp_{l}_{i}_{j}.png')\n",
    "                    left = DC_to_NFC([1 / (2 * N) + id_ / N - y1, 0])[0]\n",
    "                    right = DC_to_NFC([1 / (2 * N) + id_ / N + y1, 0])[0]\n",
    "                    bottom = DC_to_NFC([0, (l + 1 / 2) * y0 - y1])[1]\n",
    "                    up = DC_to_NFC([0, (l + 1 / 2) * y0 + y1])[1]\n",
    "                    newax = fig.add_axes([left, bottom, right - left, up - bottom])\n",
    "                    # newax = fig.add_axes([1/(2*N)+id_/N-y1, (l+1/2)*y0-y1, y1, y1], anchor='NE')\n",
    "                    if mask == False:\n",
    "                        newax.imshow(im, alpha=alpha[l][j][i])\n",
    "                    else:\n",
    "                        ### make sure to run model.prune() first to compute mask ###\n",
    "                        newax.imshow(im, alpha=alpha[l][j][i] * self.mask[l][i].item() * self.mask[l + 1][j].item())\n",
    "                    newax.axis('off')\n",
    "\n",
    "        if in_vars != None:\n",
    "            n = self.width[0]\n",
    "            for i in range(n):\n",
    "                plt.gcf().get_axes()[0].text(1 / (2 * (n)) + i / (n), -0.1, in_vars[i], fontsize=40 * scale, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "        if out_vars != None:\n",
    "            n = self.width[-1]\n",
    "            for i in range(n):\n",
    "                plt.gcf().get_axes()[0].text(1 / (2 * (n)) + i / (n), y0 * (len(self.width) - 1) + 0.1, out_vars[i], fontsize=40 * scale, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "        if title != None:\n",
    "            plt.gcf().get_axes()[0].text(0.5, y0 * (len(self.width) - 1) + 0.2, title, fontsize=40 * scale, horizontalalignment='center', verticalalignment='center')\n",
    "            \n",
    "    def train(self, dataset, opt=\"LBFGS\", steps=100, log=1, lamb=0., lamb_l1=1., lamb_entropy=2., lamb_coef=0., lamb_coefdiff=0., \n",
    "              update_grid=True, grid_update_num=10, loss_fn=None, lr=1., stop_grid_update_step=50, batch=-1,\n",
    "              small_mag_threshold=1e-16, small_reg_factor=1., metrics=None, sglr_avoid=False, save_fig=False, in_vars=None, out_vars=None, \n",
    "              beta=3, save_fig_freq=1, img_folder='./video', device='cpu'):\n",
    "        '''\n",
    "        training\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            dataset : dic\n",
    "                contains dataset['train_input'], dataset['train_label'], dataset['test_input'], dataset['test_label']\n",
    "            opt : str\n",
    "                \"LBFGS\" or \"Adam\"\n",
    "            steps : int\n",
    "                training steps\n",
    "            log : int\n",
    "                logging frequency\n",
    "            lamb : float\n",
    "                overall penalty strength\n",
    "            lamb_l1 : float\n",
    "                l1 penalty strength\n",
    "            lamb_entropy : float\n",
    "                entropy penalty strength\n",
    "            lamb_coef : float\n",
    "                coefficient magnitude penalty strength\n",
    "            lamb_coefdiff : float\n",
    "                difference of nearby coefficits (smoothness) penalty strength\n",
    "            update_grid : bool\n",
    "                If True, update grid regularly before stop_grid_update_step\n",
    "            grid_update_num : int\n",
    "                the number of grid updates before stop_grid_update_step\n",
    "            stop_grid_update_step : int\n",
    "                no grid updates after this training step\n",
    "            batch : int\n",
    "                batch size, if -1 then full.\n",
    "            small_mag_threshold : float\n",
    "                threshold to determine large or small numbers (may want to apply larger penalty to smaller numbers)\n",
    "            small_reg_factor : float\n",
    "                penalty strength applied to small factors relative to large factos\n",
    "            device : str\n",
    "                device   \n",
    "            save_fig_freq : int\n",
    "                save figure every (save_fig_freq) step\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            results : dic\n",
    "                results['train_loss'], 1D array of training losses (RMSE)\n",
    "                results['test_loss'], 1D array of test losses (RMSE)\n",
    "                results['reg'], 1D array of regularization\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> # for interactive examples, please see demos\n",
    "        >>> from utils import create_dataset\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> model.plot()\n",
    "        '''\n",
    "\n",
    "        def reg(acts_scale):\n",
    "\n",
    "            def nonlinear(x, th=small_mag_threshold, factor=small_reg_factor):\n",
    "                return (x < th) * x * factor + (x > th) * (x + (factor - 1) * th)\n",
    "\n",
    "            reg_ = 0.\n",
    "            for i in range(len(acts_scale)):\n",
    "                vec = acts_scale[i].reshape(-1, )\n",
    "\n",
    "                p = vec / torch.sum(vec)\n",
    "                l1 = torch.sum(nonlinear(vec))\n",
    "                entropy = - torch.sum(p * torch.log2(p + 1e-4))\n",
    "                reg_ += lamb_l1 * l1 + lamb_entropy * entropy  # both l1 and entropy\n",
    "\n",
    "            # regularize coefficient to encourage spline to be zero\n",
    "            for i in range(len(self.act_fun)):\n",
    "                coeff_l1 = torch.sum(torch.mean(torch.abs(self.act_fun[i].coef), dim=1))\n",
    "                coeff_diff_l1 = torch.sum(torch.mean(torch.abs(torch.diff(self.act_fun[i].coef)), dim=1))\n",
    "                reg_ += lamb_coef * coeff_l1 + lamb_coefdiff * coeff_diff_l1\n",
    "\n",
    "            return reg_\n",
    "\n",
    "        pbar = tqdm(range(steps), desc='description', ncols=100)\n",
    "\n",
    "        if loss_fn == None:\n",
    "            loss_fn = loss_fn_eval = lambda x, y: torch.mean((x - y) ** 2)\n",
    "        else:\n",
    "            loss_fn = loss_fn_eval = loss_fn\n",
    "\n",
    "        grid_update_freq = int(stop_grid_update_step / grid_update_num)\n",
    "\n",
    "        if opt == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        elif opt == \"LBFGS\":\n",
    "            optimizer = LBFGS(self.parameters(), lr=lr, history_size=10, line_search_fn=\"strong_wolfe\", tolerance_grad=1e-32, tolerance_change=1e-32, tolerance_ys=1e-32)\n",
    "\n",
    "        results = {}\n",
    "        results['train_loss'] = []\n",
    "        results['test_loss'] = []\n",
    "        results['reg'] = []\n",
    "        if metrics != None:\n",
    "            for i in range(len(metrics)):\n",
    "                results[metrics[i].__name__] = []\n",
    "\n",
    "        if batch == -1 or batch > dataset['train_input'].shape[0]:\n",
    "            batch_size = dataset['train_input'].shape[0]\n",
    "            batch_size_test = dataset['test_input'].shape[0]\n",
    "        else:\n",
    "            batch_size = batch\n",
    "            batch_size_test = batch\n",
    "\n",
    "        global train_loss, reg_\n",
    "\n",
    "        def closure():\n",
    "            global train_loss, reg_\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.forward(dataset['train_input'][train_id].to(device))\n",
    "            if sglr_avoid == True:\n",
    "                id_ = torch.where(torch.isnan(torch.sum(pred, dim=1)) == False)[0]\n",
    "                train_loss = loss_fn(pred[id_], dataset['train_label'][train_id][id_].to(device))\n",
    "            else:\n",
    "                train_loss = loss_fn(pred, dataset['train_label'][train_id].to(device))\n",
    "            reg_ = reg(self.acts_scale)\n",
    "            objective = train_loss + lamb * reg_\n",
    "            objective.backward()\n",
    "            return objective\n",
    "\n",
    "        if save_fig:\n",
    "            if not os.path.exists(img_folder):\n",
    "                os.makedirs(img_folder)\n",
    "\n",
    "        for _ in pbar:\n",
    "\n",
    "            train_id = np.random.choice(dataset['train_input'].shape[0], batch_size, replace=False)\n",
    "            test_id = np.random.choice(dataset['test_input'].shape[0], batch_size_test, replace=False)\n",
    "\n",
    "            if _ % grid_update_freq == 0 and _ < stop_grid_update_step and update_grid:\n",
    "                self.update_grid_from_samples(dataset['train_input'][train_id].to(device))\n",
    "\n",
    "            if opt == \"LBFGS\":\n",
    "                optimizer.step(closure)\n",
    "\n",
    "            if opt == \"Adam\":\n",
    "                pred = self.forward(dataset['train_input'][train_id].to(device))\n",
    "                if sglr_avoid == True:\n",
    "                    id_ = torch.where(torch.isnan(torch.sum(pred, dim=1)) == False)[0]\n",
    "                    train_loss = loss_fn(pred[id_], dataset['train_label'][train_id][id_].to(device))\n",
    "                else:\n",
    "                    train_loss = loss_fn(pred, dataset['train_label'][train_id].to(device))\n",
    "                reg_ = reg(self.acts_scale)\n",
    "                loss = train_loss + lamb * reg_\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            test_loss = loss_fn_eval(self.forward(dataset['test_input'][test_id].to(device)), dataset['test_label'][test_id].to(device))\n",
    "\n",
    "            if _ % log == 0:\n",
    "                pbar.set_description(\"train loss: %.2e | test loss: %.2e | reg: %.2e \" % (torch.sqrt(train_loss).cpu().detach().numpy(), torch.sqrt(test_loss).cpu().detach().numpy(), reg_.cpu().detach().numpy()))\n",
    "\n",
    "            if metrics != None:\n",
    "                for i in range(len(metrics)):\n",
    "                    results[metrics[i].__name__].append(metrics[i]().item())\n",
    "\n",
    "            results['train_loss'].append(torch.sqrt(train_loss).cpu().detach().numpy())\n",
    "            results['test_loss'].append(torch.sqrt(test_loss).cpu().detach().numpy())\n",
    "            results['reg'].append(reg_.cpu().detach().numpy())\n",
    "\n",
    "            if save_fig and _ % save_fig_freq == 0:\n",
    "                self.plot(folder=img_folder, in_vars=in_vars, out_vars=out_vars, title=\"Step {}\".format(_), beta=beta)\n",
    "                plt.savefig(img_folder + '/' + str(_) + '.jpg', bbox_inches='tight', dpi=200)\n",
    "                plt.close()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def prune(self, threshold=1e-2, mode=\"auto\", active_neurons_id=None):\n",
    "        '''\n",
    "        pruning KAN on the node level. If a node has small incoming or outgoing connection, it will be pruned away.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            threshold : float\n",
    "                the threshold used to determine whether a node is small enough\n",
    "            mode : str\n",
    "                \"auto\" or \"manual\". If \"auto\", the thresold will be used to automatically prune away nodes. If \"manual\", active_neuron_id is needed to specify which neurons are kept (others are thrown away).\n",
    "            active_neuron_id : list of id lists\n",
    "                For example, [[0,1],[0,2,3]] means keeping the 0/1 neuron in the 1st hidden layer and the 0/2/3 neuron in the 2nd hidden layer. Pruning input and output neurons is not supported yet.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            model2 : KAN\n",
    "                pruned model\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> # for more interactive examples, please see demos\n",
    "        >>> from utils import create_dataset\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> model.prune()\n",
    "        >>> model.plot(mask=True)\n",
    "        '''\n",
    "        mask = [torch.ones(self.width[0], )]\n",
    "        active_neurons = [list(range(self.width[0]))]\n",
    "        for i in range(len(self.acts_scale) - 1):\n",
    "            if mode == \"auto\":\n",
    "                in_important = torch.max(self.acts_scale[i], dim=1)[0] > threshold\n",
    "                out_important = torch.max(self.acts_scale[i + 1], dim=0)[0] > threshold\n",
    "                overall_important = in_important * out_important\n",
    "            elif mode == \"manual\":\n",
    "                overall_important = torch.zeros(self.width[i + 1], dtype=torch.bool)\n",
    "                overall_important[active_neurons_id[i + 1]] = True\n",
    "            mask.append(overall_important.float())\n",
    "            active_neurons.append(torch.where(overall_important == True)[0])\n",
    "        active_neurons.append(list(range(self.width[-1])))\n",
    "        mask.append(torch.ones(self.width[-1], ))\n",
    "\n",
    "        self.mask = mask  # this is neuron mask for the whole model\n",
    "\n",
    "        # update act_fun[l].mask\n",
    "        for l in range(len(self.acts_scale) - 1):\n",
    "            for i in range(self.width[l + 1]):\n",
    "                if i not in active_neurons[l + 1]:\n",
    "                    self.remove_node(l + 1, i)\n",
    "\n",
    "        model2 = KAN(copy.deepcopy(self.width), self.grid, self.k, base_fun=self.base_fun, device=self.device)\n",
    "        model2.load_state_dict(self.state_dict())\n",
    "        for i in range(len(self.acts_scale)):\n",
    "            if i < len(self.acts_scale) - 1:\n",
    "                model2.biases[i].weight.data = model2.biases[i].weight.data[:, active_neurons[i + 1]]\n",
    "\n",
    "            model2.act_fun[i] = model2.act_fun[i].get_subset(active_neurons[i], active_neurons[i + 1])\n",
    "            model2.width[i] = len(active_neurons[i])\n",
    "            model2.symbolic_fun[i] = self.symbolic_fun[i].get_subset(active_neurons[i], active_neurons[i + 1])\n",
    "\n",
    "        return model2\n",
    "\n",
    "    def remove_edge(self, l, i, j):\n",
    "        '''\n",
    "        remove activtion phi(l,i,j) (set its mask to zero)\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            l : int\n",
    "                layer index\n",
    "            i : int\n",
    "                input neuron index\n",
    "            j : int\n",
    "                output neuron index\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        '''\n",
    "        self.act_fun[l].mask[j * self.width[l] + i] = 0.\n",
    "\n",
    "    def remove_node(self, l, i):\n",
    "        '''\n",
    "        remove neuron (l,i) (set the masks of all incoming and outgoing activation functions to zero)\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            l : int\n",
    "                layer index\n",
    "            i : int\n",
    "                neuron index\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        '''\n",
    "        self.act_fun[l - 1].mask[i * self.width[l - 1] + torch.arange(self.width[l - 1])] = 0.\n",
    "        self.act_fun[l].mask[torch.arange(self.width[l + 1]) * self.width[l] + i] = 0.\n",
    "        self.symbolic_fun[l - 1].mask[i, :] *= 0.\n",
    "        self.symbolic_fun[l].mask[:, i] *= 0.\n",
    "\n",
    "    def suggest_symbolic(self, l, i, j, a_range=(-10, 10), b_range=(-10, 10), lib=None, topk=5, verbose=True):\n",
    "        '''suggest the symbolic candidates of phi(l,i,j)\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            l : int\n",
    "                layer index\n",
    "            i : int\n",
    "                input neuron index\n",
    "            j : int\n",
    "                output neuron index\n",
    "            lib : dic\n",
    "                library of symbolic bases. If lib = None, the global default library will be used.\n",
    "            topk : int\n",
    "                display the top k symbolic functions (according to r2)\n",
    "            verbose : bool\n",
    "                If True, more information will be printed.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> model = model.prune()\n",
    "        >>> model(dataset['train_input'])\n",
    "        >>> model.suggest_symbolic(0,0,0)\n",
    "        function , r2\n",
    "        sin , 0.9994412064552307\n",
    "        gaussian , 0.9196369051933289\n",
    "        tanh , 0.8608126044273376\n",
    "        sigmoid , 0.8578218817710876\n",
    "        arctan , 0.842217743396759\n",
    "        '''\n",
    "        r2s = []\n",
    "\n",
    "        if lib == None:\n",
    "            symbolic_lib = SYMBOLIC_LIB\n",
    "        else:\n",
    "            symbolic_lib = {}\n",
    "            for item in lib:\n",
    "                symbolic_lib[item] = SYMBOLIC_LIB[item]\n",
    "\n",
    "        for (name, fun) in symbolic_lib.items():\n",
    "            r2 = self.fix_symbolic(l, i, j, name, a_range=a_range, b_range=b_range, verbose=False)\n",
    "            r2s.append(r2.item())\n",
    "\n",
    "        self.unfix_symbolic(l, i, j)\n",
    "\n",
    "        sorted_ids = np.argsort(r2s)[::-1][:topk]\n",
    "        r2s = np.array(r2s)[sorted_ids][:topk]\n",
    "        topk = np.minimum(topk, len(symbolic_lib))\n",
    "        if verbose == True:\n",
    "            print('function', ',', 'r2')\n",
    "            for i in range(topk):\n",
    "                print(list(symbolic_lib.items())[sorted_ids[i]][0], ',', r2s[i])\n",
    "\n",
    "        best_name = list(symbolic_lib.items())[sorted_ids[0]][0]\n",
    "        best_fun = list(symbolic_lib.items())[sorted_ids[0]][1]\n",
    "        best_r2 = r2s[0]\n",
    "        return best_name, best_fun, best_r2\n",
    "\n",
    "    def auto_symbolic(self, a_range=(-10, 10), b_range=(-10, 10), lib=None, verbose=1):\n",
    "        '''\n",
    "        automatic symbolic regression: using top 1 suggestion from suggest_symbolic to replace splines with symbolic activations\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            lib : None or a list of function names\n",
    "                the symbolic library\n",
    "            verbose : int\n",
    "                verbosity\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None (print suggested symbolic formulas)\n",
    "\n",
    "        Example 1\n",
    "        ---------\n",
    "        >>> # default library\n",
    "        >>> from utils import create_dataset\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> >>> model = model.prune()\n",
    "        >>> model(dataset['train_input'])\n",
    "        >>> model.auto_symbolic()\n",
    "        fixing (0,0,0) with sin, r2=0.9994837045669556\n",
    "        fixing (0,1,0) with cosh, r2=0.9978033900260925\n",
    "        fixing (1,0,0) with arctan, r2=0.9997088313102722\n",
    "\n",
    "        Example 2\n",
    "        ---------\n",
    "        >>> # customized library\n",
    "        >>> from utils import create_dataset\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> >>> model = model.prune()\n",
    "        >>> model(dataset['train_input'])\n",
    "        >>> model.auto_symbolic(lib=['exp','sin','x^2'])\n",
    "        fixing (0,0,0) with sin, r2=0.999411404132843\n",
    "        fixing (0,1,0) with x^2, r2=0.9962921738624573\n",
    "        fixing (1,0,0) with exp, r2=0.9980258941650391\n",
    "        '''\n",
    "        for l in range(len(self.width) - 1):\n",
    "            for i in range(self.width[l]):\n",
    "                for j in range(self.width[l + 1]):\n",
    "                    if self.symbolic_fun[l].mask[j, i] > 0.:\n",
    "                        print(f'skipping ({l},{i},{j}) since already symbolic')\n",
    "                    else:\n",
    "                        name, fun, r2 = self.suggest_symbolic(l, i, j, a_range=a_range, b_range=b_range, lib=lib,\n",
    "                                                              verbose=False)\n",
    "                        self.fix_symbolic(l, i, j, name, verbose=verbose > 1)\n",
    "                        if verbose >= 1:\n",
    "                            print(f'fixing ({l},{i},{j}) with {name}, r2={r2}')\n",
    "\n",
    "    def symbolic_formula(self, floating_digit=2, var=None, normalizer=None, simplify=False, output_normalizer=None):\n",
    "        '''\n",
    "        obtain the symbolic formula\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            floating_digit : int\n",
    "                the number of digits to display\n",
    "            var : list of str\n",
    "                the name of variables (if not provided, by default using ['x_1', 'x_2', ...])\n",
    "            normalizer : [mean array (floats), varaince array (floats)]\n",
    "                the normalization applied to inputs\n",
    "            simplify : bool\n",
    "                If True, simplify the equation at each step (usually quite slow), so set up False by default.\n",
    "            output_normalizer: [mean array (floats), varaince array (floats)]\n",
    "                the normalization applied to outputs\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            symbolic formula : sympy function\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0, grid_eps=0.02)\n",
    "        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "        >>> dataset = create_dataset(f, n_var=2)\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n",
    "        >>> model = model.prune()\n",
    "        >>> model(dataset['train_input'])\n",
    "        >>> model.auto_symbolic(lib=['exp','sin','x^2'])\n",
    "        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.00, update_grid=False);\n",
    "        >>> model.symbolic_formula()\n",
    "        '''\n",
    "        symbolic_acts = []\n",
    "        x = []\n",
    "\n",
    "        def ex_round(ex1, floating_digit=floating_digit):\n",
    "            ex2 = ex1\n",
    "            for a in sympy.preorder_traversal(ex1):\n",
    "                if isinstance(a, sympy.Float):\n",
    "                    ex2 = ex2.subs(a, round(a, floating_digit))\n",
    "            return ex2\n",
    "\n",
    "        # define variables\n",
    "        if var == None:\n",
    "            for ii in range(1, self.width[0] + 1):\n",
    "                exec(f\"x{ii} = sympy.Symbol('x_{ii}')\")\n",
    "                exec(f\"x.append(x{ii})\")\n",
    "        else:\n",
    "            x = [sympy.symbols(var_) for var_ in var]\n",
    "\n",
    "        x0 = x\n",
    "\n",
    "        if normalizer != None:\n",
    "            mean = normalizer[0]\n",
    "            std = normalizer[1]\n",
    "            x = [(x[i] - mean[i]) / std[i] for i in range(len(x))]\n",
    "\n",
    "        symbolic_acts.append(x)\n",
    "\n",
    "        for l in range(len(self.width) - 1):\n",
    "            y = []\n",
    "            for j in range(self.width[l + 1]):\n",
    "                yj = 0.\n",
    "                for i in range(self.width[l]):\n",
    "                    a, b, c, d = self.symbolic_fun[l].affine[j, i]\n",
    "                    sympy_fun = self.symbolic_fun[l].funs_sympy[j][i]\n",
    "                    try:\n",
    "                        yj += c * sympy_fun(a * x[i] + b) + d\n",
    "                    except:\n",
    "                        print('make sure all activations need to be converted to symbolic formulas first!')\n",
    "                        return\n",
    "                if simplify == True:\n",
    "                    y.append(sympy.simplify(yj + self.biases[l].weight.data[0, j]))\n",
    "                else:\n",
    "                    y.append(yj + self.biases[l].weight.data[0, j])\n",
    "\n",
    "            x = y\n",
    "            symbolic_acts.append(x)\n",
    "\n",
    "        if output_normalizer != None:\n",
    "            output_layer = symbolic_acts[-1]\n",
    "            means = output_normalizer[0]\n",
    "            stds = output_normalizer[1]\n",
    "\n",
    "            assert len(output_layer) == len(means), 'output_normalizer does not match the output layer'\n",
    "            assert len(output_layer) == len(stds), 'output_normalizer does not match the output layer'\n",
    "\n",
    "            output_layer = [(output_layer[i] * stds[i] + means[i]) for i in range(len(output_layer))]\n",
    "            symbolic_acts[-1] = output_layer\n",
    "\n",
    "        self.symbolic_acts = [[ex_round(symbolic_acts[l][i]) for i in range(len(symbolic_acts[l]))] for l in\n",
    "                              range(len(symbolic_acts))]\n",
    "\n",
    "        out_dim = len(symbolic_acts[-1])\n",
    "        return [ex_round(symbolic_acts[-1][i]) for i in range(len(symbolic_acts[-1]))], x0\n",
    "\n",
    "    def clear_ckpts(self, folder='./model_ckpt'):\n",
    "        '''\n",
    "        clear all checkpoints\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            folder : str\n",
    "                the folder that stores checkpoints\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        '''\n",
    "        if os.path.exists(folder):\n",
    "            files = glob.glob(folder + '/*')\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "        else:\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def save_ckpt(self, name, folder='./model_ckpt'):\n",
    "        '''\n",
    "        save the current model as checkpoint\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            name: str\n",
    "                the name of the checkpoint to be saved\n",
    "            folder : str\n",
    "                the folder that stores checkpoints\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        '''\n",
    "\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        torch.save(self.state_dict(), folder + '/' + name)\n",
    "        print('save this model to', folder + '/' + name)\n",
    "\n",
    "    def load_ckpt(self, name, folder='./model_ckpt'):\n",
    "        '''\n",
    "        load a checkpoint to the current model\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            name: str\n",
    "                the name of the checkpoint to be loaded\n",
    "            folder : str\n",
    "                the folder that stores checkpoints\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        '''\n",
    "        self.load_state_dict(torch.load(folder + '/' + name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:17:36.654633Z",
     "start_time": "2024-05-20T09:17:36.430786100Z"
    }
   },
   "id": "8a01bea51d1a9e78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# a simple example 一个简单的测试\n",
    "## 使用KAN网络拟合一个函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a2132fc8c092c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.初始化 KAN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6950e9cb358ccf46"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_default_dtype(torch.float64) # 设置默认张量数据类型为双精度浮点数\n",
    "torch.manual_seed(33) # 设置随机数种子为33\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 创建一个KAN模型：\n",
    "# 输入维度为2，输出维度为1，隐藏层有5个神经元\n",
    "# 使用三次样条（k=3），将输入空间划分为5个网格间隔（grid=5）\n",
    "# 设置随机数种子为0\n",
    "model = KAN(width=[2,5,1], grid=5, k=3, seed=0,device=device)\n",
    "# 打印参数数量\n",
    "print('number of parameters:', sum(p.numel() for p in model.parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:20.919213500Z",
     "start_time": "2024-05-20T09:19:20.874854800Z"
    }
   },
   "id": "49a24659bcb56754"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.创建数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d09cd94f3f4f47a5"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义数据集函数 f(x,y) = exp(sin(pi*x) + y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "# 使用 create_dataset 函数创建数据集\n",
    "# 数据集包含两个自变量（n_var=2）\n",
    "# 数据集会根据设备 device 进行处理\n",
    "dataset = create_dataset(f, n_var=2,device=device)\n",
    "# 打印训练输入和标签的形状\n",
    "dataset['train_input'].shape, dataset['train_label'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:22.043523600Z",
     "start_time": "2024-05-20T09:19:22.010931800Z"
    }
   },
   "id": "79ddde589b91508c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.符号化初始化的KAN网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e374f59400958098"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 16 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制初始化时的KAN模型图形\n",
    "model(dataset['train_input'])\n",
    "# 使用 plot 方法绘制模型的输出结果\n",
    "# 设置 beta 参数为 100，用于控制平滑度\n",
    "model.plot(beta=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:25.287894700Z",
     "start_time": "2024-05-20T09:19:23.893193200Z"
    }
   },
   "id": "1b28646d44605e55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.使用稀疏正则化训练 KAN 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "131de2e628e3e841"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.22e-01 | test loss: 1.11e-01 | reg: 1.89e+01 : 100%|██| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train_loss': [array(0.17774457),\n  array(0.1649384),\n  array(0.13739218),\n  array(0.12844005),\n  array(0.12625518),\n  array(0.13579312),\n  array(0.12902339),\n  array(0.12892272),\n  array(0.12651465),\n  array(0.12267715),\n  array(0.12234461),\n  array(0.12158098),\n  array(0.12153054),\n  array(0.12159392),\n  array(0.12190735),\n  array(0.12203006),\n  array(0.12210499),\n  array(0.12218641),\n  array(0.12202529),\n  array(0.1219473)],\n 'test_loss': [array(0.1680343),\n  array(0.15144043),\n  array(0.1188317),\n  array(0.11041944),\n  array(0.11736412),\n  array(0.12754529),\n  array(0.11984469),\n  array(0.12004567),\n  array(0.11717632),\n  array(0.11198748),\n  array(0.11151643),\n  array(0.11048052),\n  array(0.11041521),\n  array(0.1104983),\n  array(0.1109166),\n  array(0.1110628),\n  array(0.11116022),\n  array(0.11126267),\n  array(0.11104261),\n  array(0.11093857)],\n 'reg': [array(51.92453039),\n  array(29.7866107),\n  array(21.74755223),\n  array(20.69949648),\n  array(20.04275557),\n  array(19.7303089),\n  array(19.33570847),\n  array(19.2413265),\n  array(19.19517901),\n  array(19.18071867),\n  array(19.1749032),\n  array(19.08932477),\n  array(19.04255113),\n  array(19.0034848),\n  array(18.9704363),\n  array(18.95502555),\n  array(18.94065012),\n  array(18.9253424),\n  array(18.90618593),\n  array(18.90512782)]}"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对模型进行训练\n",
    "# 使用 LBFGS 优化器\n",
    "# 进行 20 步训练\n",
    "# 设置正则化参数为 0.01\n",
    "# 设置信息熵正则化参数为 10.0\n",
    "# 在给定的设备上进行训练\n",
    "model.train(dataset, opt=\"LBFGS\", steps=20, lamb=0.01, lamb_entropy=10.,device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:43.378073400Z",
     "start_time": "2024-05-20T09:19:28.680765200Z"
    }
   },
   "id": "8aab3953bff70a48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.符号化训练后的KAN网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1986aaabef16f7f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 16 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot() # 使用 plot 方法绘制训练后的KAN模型"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:51.474913400Z",
     "start_time": "2024-05-20T09:19:49.883065Z"
    }
   },
   "id": "de3b0f4ffd91753f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.剪枝，再绘制（保持原网络结构）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee897dbf5e2daba3"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 16 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对KAN模型进行修剪\n",
    "model.prune()\n",
    "# 使用 plot 方法绘制修剪后的KAN模型\n",
    "# 设置 mask=True 以保持原始形状\n",
    "model.plot(mask=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:54.567673100Z",
     "start_time": "2024-05-20T09:19:52.970478700Z"
    }
   },
   "id": "597f2e1ed685855"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.剪枝，再绘制（得到更小的网络结构）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c7391fbb1214def"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 4 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 修剪KAN模型，并将修剪后的模型重新赋值给原来的模型变量\n",
    "model = model.prune()\n",
    "# 使用修剪后的模型对训练输入数据进行预测\n",
    "model(dataset['train_input'])\n",
    "# 使用 plot 方法绘制修剪后的KAN模型的输出结果\n",
    "model.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:19:56.141070Z",
     "start_time": "2024-05-20T09:19:55.736951900Z"
    }
   },
   "id": "f5acb7353285d403"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.继续训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ef3974807dfb32"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 4.71e-03 | test loss: 4.74e-03 | reg: 2.85e+00 : 100%|██| 50/50 [00:19<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# 继续对模型进行训练\n",
    "# 使用 LBFGS 优化器\n",
    "# 进行 50 步训练\n",
    "# 在给定的设备上进行训练\n",
    "model.train(dataset, opt=\"LBFGS\", steps=50,device=device);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:20:16.407325500Z",
     "start_time": "2024-05-20T09:19:57.333857800Z"
    }
   },
   "id": "df962d205e390850"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.绘制"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b85f5afa6a919834"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 4 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot() # 使用 plot 方法绘制模型的输出结果"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:20:21.650998300Z",
     "start_time": "2024-05-20T09:20:21.292082300Z"
    }
   },
   "id": "44ab6e6366cc6e48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10.自动或手动设置激活函数为符号函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd8ed2fbbdd9c9a9"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing (0,0,0) with sin, r2=0.9999872981947846\n",
      "fixing (0,1,0) with x^2, r2=0.9999995774611793\n",
      "fixing (1,0,0) with exp, r2=0.9999989642148466\n"
     ]
    }
   ],
   "source": [
    "# 设置 mode 变量为 \"auto\" 或 \"manual\"，以确定激活函数的设置方式\n",
    "mode = \"auto\"  # 或者 mode = \"manual\"\n",
    "# 如果 mode 是 \"manual\"，则手动设置激活函数为符号函数\n",
    "if mode == \"manual\":\n",
    "    # 手动模式下，逐个指定隐藏层和输入层的激活函数\n",
    "    # 第一个参数表示层的索引，第二个和第三个参数表示神经元的索引\n",
    "    # 第四个参数为要设置的激活函数，例如 'sin', 'x^2', 'exp' 等\n",
    "    model.fix_symbolic(0,0,0,'sin'); # 设置第一个隐藏层的第一个神经元的激活函数为正弦函数\n",
    "    model.fix_symbolic(0,1,0,'x^2'); # 设置第一个隐藏层的第二个神经元的激活函数为平方函数\n",
    "    model.fix_symbolic(1,0,0,'exp'); # 设置输出层的第一个神经元的激活函数为指数函数\n",
    "# 如果 mode 是 \"auto\"，则自动设置激活函数为符号函数\n",
    "elif mode == \"auto\":\n",
    "    # 自动模式下，根据提供的激活函数库自动选择合适的符号函数作为激活函数\n",
    "    lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
    "    model.auto_symbolic(lib=lib)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:20:24.151272400Z",
     "start_time": "2024-05-20T09:20:22.900154300Z"
    }
   },
   "id": "644d8e962e5746be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 11.继续训练达到机器精度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "639c0381759ac8ca"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 7.45e-10 | test loss: 7.64e-10 | reg: 2.85e+00 : 100%|██| 50/50 [00:06<00:00,  8.14it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset, opt=\"LBFGS\",steps=50,device=device); # 继续对模型进行训练"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:20:32.727201800Z",
     "start_time": "2024-05-20T09:20:26.558866Z"
    }
   },
   "id": "e6258b5a86d2387c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 12.得到数学表达式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc87e83dac2b803"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0*exp(1.0*x_2**2 + 1.0*sin(3.14*x_1))",
      "text/latex": "$\\displaystyle 1.0 e^{1.0 x_{2}^{2} + 1.0 \\sin{\\left(3.14 x_{1} \\right)}}$"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.symbolic_formula()[0][0] # 获取模型的符号化公式\n",
    "\n",
    "# f(x,y) = exp(sin(pi*x)+y^2)\n",
    "# 几乎完美复现"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:20:33.934132200Z",
     "start_time": "2024-05-20T09:20:33.912900900Z"
    }
   },
   "id": "ebfe4bed40fd1e5b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:18:23.478087400Z",
     "start_time": "2024-05-20T09:18:23.461226700Z"
    }
   },
   "id": "9cba3cb3bd93c62"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:18:23.519003300Z",
     "start_time": "2024-05-20T09:18:23.476087500Z"
    }
   },
   "id": "fc600f337d57d61c"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:18:23.530232600Z",
     "start_time": "2024-05-20T09:18:23.491101600Z"
    }
   },
   "id": "1bd58f76b76934fb"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:18:23.530232600Z",
     "start_time": "2024-05-20T09:18:23.507499200Z"
    }
   },
   "id": "24e85d81a98bb6a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
